{
  "hash": "944b6f6d27a067e225d467ece779d5f0",
  "result": {
    "markdown": "---\ntitle: \"Logistic\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Introduction\n\nLogistic regression is used when the outcome variable is discrete and binary, which is called classification. Multinomial logistic regression can classify observations into more than two categories, but we are only doing simple logistic regression here, with two categories. We use the inverse logit function to model the probability that $Y_i = 1$.\n\n$$\nlogit^{-1}(x)=\\frac{e^x}{1+e^x} \\\\\nPr(y_i=1) = logit^{-1}(X_i\\beta)\n$$`plogis` is the invlogit function.\n\n## Uses\n\nLogistic regression is good for when covariates are continuous, as the outcome variables are bounded between 0 and 1, through the logit link.\n\n## Assumptions\n\n1.  For binary logistic regression, that outcome variables are binary\n2.  Independence of errors\n3.  Linear relationship between the outcome variable and log odds of the predictor variables\n4.  No multicollinearity\n\n## Our Logistic Regression Implementation\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nlibrary(alr4)\n# invlogit <- plogis\n\nlogistic_function <- function(fn_formula, data, predict = F) {\n  number_omitted <- nrow(data) - nrow(na.omit(data))\n  data <- na.omit(data)\n\n  vars <- all.vars(as.formula(fn_formula))\n  y_name <- vars[1]\n  x_name <- vars[2:length(vars)]\n  n <- nrow(data)\n  Y <- matrix(data[, y_name], nrow = n, ncol = 1)\n  X <- matrix(cbind(rep(1, n)))\n\n  # take in categorical data\n  var_names <- vector(\"character\")\n  for (i in x_name) {\n    if (suppressWarnings(all(!is.na(as.numeric(as.character(data[, i])))))) {\n      X <- cbind(X, as.numeric(as.character(data[, i])))\n      var_names <- c(var_names, i)\n    } else {\n      categories <- sort(unique(data[, i]))\n      for (j in categories[2:length(categories)]) {\n        new_col_name <- paste0(i, j)\n        new_col <- ifelse(data[, i] == j, 1, 0)\n        X <- cbind(X, new_col)\n        var_names <- c(var_names, new_col_name)\n      }\n    }\n  }\n  optim_logistic <- function(beta, X, Y) {\n    beta <- as.matrix(beta, nrow = 4)\n    pi <- plogis(X %*% beta)\n    loglikelihood <- -sum(Y * log(pi) + (1 - Y) * log(1 - pi))\n    return(loglikelihood)\n  }\n  result <- optim(par = rep(0, ncol(X)), fn = optim_logistic, X = X, Y = Y, hessian = T)\n  OI <- solve(result$hessian)\n  se <- sqrt(diag(OI))\n  t_statistic <- result$par / se\n  df <- nrow(X) - ncol(X)\n  p_value <- 2 * pnorm(-1 * abs(t_statistic))\n  # https://stats.stackexchange.com/questions/52475/how-are-the-p-values-of-the-glm-in-r-calculated\n\n  coef <- rbind(result$par, se, t_statistic, p_value)\n  colnames(coef) <- c(\"(Intercept)\", var_names)\n  rownames(coef) <- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n  coef <- t(coef)\n\n  b_hat <- result$par\n  predictions <- plogis(X %*% b_hat)\n\n  if (predict) {\n    return(predictions)\n  } else {\n    return(coef)\n  }\n}\n```\n:::\n\n\nCreating testing data set with a single predictor variable to compare our implementation with `glm` logistic function\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# create fake data\nx1 <- rnorm(100, 2, 1)\nprob <- plogis(-1 + 0.5 * x1)\ny <- rbinom(100, 1, prob)\nsim_data <- data.frame(y, x1)\n\n# compare DIY logistic function with glm\nfit_sim_data_1 <- glm(y ~ x1, data = sim_data, family = binomial)\nsummary(fit_sim_data_1)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error   z value   Pr(>|z|)\n(Intercept) -0.7456721  0.5316508 -1.402560 0.16074811\nx1           0.5410003  0.2427422  2.228703 0.02583366\n```\n:::\n\n```{.r .cell-code}\nlogistic_function(fn_formula = \"y ~ x1\", data = sim_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error   z value    p value\n(Intercept) -0.7459709  0.5316604 -1.403097 0.16058801\nx1           0.5410940  0.2427464  2.229051 0.02581053\n```\n:::\n\n```{.r .cell-code}\n# checking for linear relationship\nplot(sim_data$x1, prob,\n  main = \"The log odds of y and x1 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x1\", ylab = \"y\"\n)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-3-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\n# check for correlation of residuals vs fit\nplot(fit_sim_data_1, which = 1)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-3-2.png){fig-align='left' width=8.5in}\n:::\n:::\n\n\nCreating testing data set with multiple covariates to compare our implementation with `glm` logistic function\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# create fake data with multiple x's\nx1 <- rnorm(100, 2, 1)\nx2 <- rnorm(100, 4, 1)\nx3 <- rnorm(100, 6, 1)\nprob <- plogis(-1 + x1 + x2 - 0.5 * x3)\ny <- rbinom(100, 1, prob)\nsim_data <- data.frame(y, x1, x2, x3)\n\n# compare DIY logistic function with glm\nfit_sim_data <- glm(y ~ x1 + x2 + x3, data = sim_data, family = binomial)\nsummary(fit_sim_data)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error    z value    Pr(>|z|)\n(Intercept)  2.4011218  2.4617714  0.9753634 0.329380012\nx1           1.3097873  0.4646174  2.8190663 0.004816356\nx2           0.9528707  0.3591008  2.6534911 0.007966387\nx3          -1.1133007  0.3837826 -2.9008631 0.003721364\n```\n:::\n\n```{.r .cell-code}\nlogistic_function(fn_formula = \"y ~ x1 + x2 + x3\", data = sim_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error    z value     p value\n(Intercept)  2.4003220  2.4618335  0.9750139 0.329553343\nx1           1.3102691  0.4646817  2.8197132 0.004806659\nx2           0.9530523  0.3591195  2.6538587 0.007957715\nx3          -1.1134496  0.3838115 -2.9010321 0.003719358\n```\n:::\n:::\n\n\nUsing the alr4 Donner data to test categorical data, and compare our implementation with `glm` logistic function\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nDonner$survived <- Donner$y == \"survived\"\nfit_Donner <- glm(survived ~ age + sex + status, data = Donner, family = \"binomial\")\nsummary(fit_Donner)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                Estimate   Std. Error      z value    Pr(>|z|)\n(Intercept)    1.4873491 4.926432e-01  3.019120666 0.002535095\nage           -0.0281043 1.504262e-02 -1.868311545 0.061718658\nsexMale       -0.7279889 5.172218e-01 -1.407498622 0.159279585\nstatusHired   -0.5985928 6.281956e-01 -0.952876467 0.340652665\nstatusSingle -17.4555740 1.765537e+03 -0.009886838 0.992111573\n```\n:::\n\n```{.r .cell-code}\nlogistic_function(fn_formula = \"survived ~ age + sex + status\", data = Donner)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                Estimate  Std. Error    z value     p value\n(Intercept)   1.50395496  0.49431184  3.0425226 0.002346042\nage          -0.02838637  0.01507534 -1.8829672 0.059704810\nsexMale      -0.74855738  0.51805480 -1.4449386 0.148475138\nstatusHired  -0.58665853  0.62833280 -0.9336748 0.350471646\nstatusSingle -6.48117449 12.14886686 -0.5334798 0.593701523\n```\n:::\n:::\n\n\n**Interpretation of the coefficients**\n\nA 1-unit difference in age corresponds to -0.02 in the logit probability of having survived in the Donner party, or a multiplicative change of $e^{-0.0283}=0.972$ in the odds of surviving.\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nggplot(Donner) +\n  geom_jitter(aes(x = age, y = survived, color = survived)) +\n  facet_wrap(vars(status)) +\n  ggtitle(\"Younger people generally had a higher chance of surviving\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-6-1.png){fig-align='left' width=8.5in}\n:::\n:::\n\n\nShow that our implementation of logistic regression can also make predictions\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nidx <- sample(1:nrow(Donner), 5)\np1 <- logistic_function(fn_formula = \"survived ~ age + sex + status\", data = Donner, predict = T)[idx, ]\np2 <- predict(fit_Donner, type = \"response\")[idx]\ncompare_predict_data <- data.frame(p1, p2)\ncolnames(compare_predict_data) <- c(\"Our implementation\", \"GLM\")\n\nkable(compare_predict_data, digits = 3, caption = \"Comparison of logistic prediction\", booktabs = TRUE, valign = \"t\") |> kable_styling(latex_options = \"HOLD_position\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Comparison of logistic prediction</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Our implementation </th>\n   <th style=\"text-align:right;\"> GLM </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Breen_Margaret_Isabella </td>\n   <td style=\"text-align:right;\"> 0.814 </td>\n   <td style=\"text-align:right;\"> 0.811 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Breen_Patrick </td>\n   <td style=\"text-align:right;\"> 0.334 </td>\n   <td style=\"text-align:right;\"> 0.338 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Spitzer_Augustus </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Donner_Isaac </td>\n   <td style=\"text-align:right;\"> 0.649 </td>\n   <td style=\"text-align:right;\"> 0.650 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Foster_Sarah_Ann_Charlotte_Murphy </td>\n   <td style=\"text-align:right;\"> 0.724 </td>\n   <td style=\"text-align:right;\"> 0.722 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Function to check assumptions\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\ntest_logistic_assumptions <- function(fn_formula, data) {\n  n <- nrow(data)\n  vars <- all.vars(as.formula(fn_formula))\n  y_name <- vars[1]\n  Y <- data[, y_name]\n\n  # outcome variables are binary\n  if (length(unique(Y)) == 2) {\n    assp_1 <- paste(\"Binary outcomes assumption is met.\")\n  } else {\n    return(paste(\"Binary outcomes assumption is not satisfied. There are\", length(unique(Y)), \"outcomes.\"))\n  }\n\n  x_name <- vars[2:length(vars)]\n  X <- data[, x_name]\n  preds <- logistic_function(fn_formula = fn_formula, data = data, predict = T) # predictions are in probability\n  logit_vals <- log(preds / (1 - preds))\n  plot_data <- data.frame(logit_vals, X) |> gather(key = \"predictors\", value = \"predictor_value\", -logit_vals)\n\n  # Linear relationship between the outcome variable and log odds of the predictor variables\n  assp_2 <- ggplot(plot_data, aes(logit_vals, predictor_value)) +\n    geom_point(size = 0.5, alpha = 0.5) +\n    geom_smooth(method = \"loess\") +\n    theme_bw() +\n    facet_wrap(~predictors, scales = \"free_y\")\n\n  # Independence of errors\n  # plot residuals vs fits\n  model <- glm(fn_formula, data = data, family = binomial)\n  assp_3 <- plot(model, which = 1)\n\n  # No multicollinearity\n  assp_4 <- cor(data[, -1])\n\n  predicted.values <- ifelse(preds >= 0.5, 1, 0)\n  check_perf <- data.frame(Y, predicted.values) |> mutate(correct = Y == predicted.values)\n  check_perf <- paste0(mean(check_perf$correct) * 100, \"% classified correctly\")\n  return(list(assp_1, assp_2, print(assp_3), assp_4, check_perf))\n}\n\nn <- 200\nx1 <- rnorm(n, 2, 1)\nx2 <- rnorm(n, 4, 1)\nprob <- plogis(-1 + 1.2 * x1 - 0.5 * x2)\nhist(prob)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-8-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\ny <- rbinom(n, 1, prob)\nsim_data <- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = sim_data)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-8-2.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-8-3.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n[[3]]\nNULL\n\n[[4]]\n          x1        x2\nx1  1.000000 -0.018217\nx2 -0.018217  1.000000\n\n[[5]]\n[1] \"78.5% classified correctly\"\n```\n:::\n:::\n\n\n1.  For binary logistic regression, that outcome variables are binary\n\n    Check how many unique outcome variables there are.\n\n2.  Independence of errors\n\n    Check residual plots.\n\n3.  Linear relationship between the outcome variable and log odds of the predictor variables\n\n    Check scatterplots of log odds vs predictor variables to see that there is an approximately linear relationship.\n\n4.  No multicollinearity\n\n    Look at the correlation matrix, generally any value over 0.9 is problematic.\n\n## Breaking assumptions\n\n#### 1. For binary logistic regression, that outcome variables are binary\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- rnorm(n, 2, 1)\nprob <- plogis(-1 + 0.8 * x1)\ny <- rpois(n, prob)\nbad_data <- data.frame(y, x1)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1\", data = bad_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Binary outcomes assumption is not satisfied. There are 4 outcomes.\"\n```\n:::\n:::\n\n\n#### 2. Independence of errors\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- rnorm(n, 2, 1)\nx2 <- rnorm(n, 0, 1)\nprob <- plogis(-1.2 + 0.4 * x1 + 0.3 * x2 + rbeta(n, 2, 2))\nhist(prob)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-10-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\ny <- rbinom(n, 1, prob)\nbad_data <- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = bad_data)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-10-2.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-10-3.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n[[3]]\nNULL\n\n[[4]]\n           x1         x2\nx1 1.00000000 0.09361225\nx2 0.09361225 1.00000000\n\n[[5]]\n[1] \"62% classified correctly\"\n```\n:::\n:::\n\n\nI used `rbeta` to introduce more error for the middle of the probabilities, which shows in the residual plot, where it looks like there is a peak in the fitted line around 0.\n\n#### 3. Linear relationship between the outcome variable and log odds of the predictor variables\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- rnorm(n, 0, 1)\nx2 <- rnorm(n, 2, 1)\nx3 <- rnorm(n, -2, 1)\nprob <- plogis(-1 + x1 * x2 + 1.3 * x2 - 0.5 * x3^2)\nhist(prob)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-11-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\ny <- rbinom(n, 1, prob)\nbad_data <- data.frame(y, x1, x2, x3)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2 + x3\", data = bad_data)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-11-2.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-11-3.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n[[3]]\nNULL\n\n[[4]]\n           x1          x2          x3\nx1  1.0000000 -0.16860022 -0.17308515\nx2 -0.1686002  1.00000000  0.02992617\nx3 -0.1730851  0.02992617  1.00000000\n\n[[5]]\n[1] \"82% classified correctly\"\n```\n:::\n:::\n\n\nFor the probability used in the DGP, it is no longer a linear relationship of $X_i\\beta$ but one that involves interactions and squared variables. The non-linear relationship is visible in the plots of the outcome variable vs log odds of each predictor variable.\n\n#### 4. No multicollinearity\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- rnorm(n, 0, 1)\nx2 <- rnorm(n, x1, 0.2)\nprob <- plogis(-1 + x1 + 0.5 * x2)\nhist(prob)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-12-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\ny <- rbinom(n, 1, prob)\nbad_data <- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = bad_data)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-12-2.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](logistic_files/figure-html/unnamed-chunk-12-3.png){fig-align='left' width=8.5in}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n[[3]]\nNULL\n\n[[4]]\n          x1        x2\nx1 1.0000000 0.9847734\nx2 0.9847734 1.0000000\n\n[[5]]\n[1] \"80% classified correctly\"\n```\n:::\n:::\n\n\nThe DGP involves $x2$ being created from an `rnorm` around the mean of $x1$, and a small SD so that it is even more correlated. The correlation matrix shows a problematically high correlation. The model still classifies fairly well, but what happens with multicollinearity is that it becomes difficult for the model to estimate the relationship between each predictor variable and the outcome variable independently because the predictor variables tend to change in unison. The p-values are also less trustworthy.\n\n## Next Steps\n\n-   Instead of just using maximum likelihood, we could try using iteratively reweighted least squares or Newton-Ralphson.\n\n## Conclusion\n\nBreaking certain assumptions do not make the logistic model classify worse. Independence of errors seems to be the worst case, but the rest do not change the correct classification rate much.\n",
    "supporting": [
      "logistic_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}