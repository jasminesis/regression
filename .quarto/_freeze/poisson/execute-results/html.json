{
  "hash": "a7343cc419c2af4102cdc0133f02fc0c",
  "result": {
    "markdown": "---\ntitle: \"Poisson\"\n---\n\n::: {.cell}\n\n:::\n\n\n## Introduction\n\nPoisson regression is used for count and rate data. We use Poisson distribution to model the expected value of $Y$, which is denoted by $E(Y) = \\mu$. The identity link is the log link, so the Poisson regression model for counts is $log(\\mu) = \\alpha + \\beta x$. The Poisson distribution with parameter $\\lambda$, $Poi(\\lambda)$ has the probability mass function\n\n$$\nP(X=k) = exp(-\\lambda)\\frac{\\lambda^k}{k!}, k=0,1,2,3,...\n$$\n\n## Uses\n\nPoisson regression can be used for count data, such as number of asthmatic attacks in one year based on the number of hospital admissions and systolic blood pressure. When the predictor variables are continuous, poisson regression ensures that the outcome variable is positive, compared to a linear regression which might predict negative counts. Another use case for Poisson regression is when the number of cases is small relative to the number of no events, such as when the number of deaths due to COVID-19 are small relative to the total population size. Logistic regression is more useful when we have data on both the binary outcomes (e.g. death and non-deaths).\n\n## Assumptions\n\n-   outcome variable must be count data\n-   Independent observations\n-   Distribution of counts follow a Poisson distribution\n-   No overdispersion - the mean and variance of the distribution are equal. If the variance is greater than the mean, negative binomial regression may be more appropriate\n\n## Our Poisson Regression Implementation\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\npoisson_function <- function(fn_formula, data, predict = F) {\n  number_omitted <- nrow(data) - nrow(na.omit(data))\n  data <- na.omit(data)\n\n  vars <- all.vars(as.formula(fn_formula))\n  y_name <- vars[1]\n  x_name <- vars[2:length(vars)]\n  n <- nrow(data)\n  Y <- matrix(data[, y_name], nrow = n, ncol = 1)\n  X <- matrix(cbind(rep(1, n)))\n\n  # take in categorical data\n  var_names <- vector(\"character\")\n  for (i in x_name) {\n    if (suppressWarnings(all(!is.na(as.numeric(as.character(data[, i])))))) {\n      X <- cbind(X, as.numeric(as.character(data[, i])))\n      var_names <- c(var_names, i)\n    } else {\n      categories <- sort(unique(data[, i]))\n      for (j in categories[2:length(categories)]) {\n        new_col_name <- paste0(i, j)\n        new_col <- ifelse(data[, i] == j, 1, 0)\n        X <- cbind(X, new_col)\n        var_names <- c(var_names, new_col_name)\n      }\n    }\n  }\n  optim_poisson <- function(beta, X, Y) {\n    beta <- as.matrix(beta, nrow = 4)\n    beta_x <- X %*% beta\n    loglikelihood <- -sum(Y * beta_x - exp(beta_x))\n    return(loglikelihood)\n  }\n  result <- optim(par = rep(0, ncol(X)), fn = optim_poisson, X = X, Y = Y, hessian = T)\n  OI <- solve(result$hessian)\n  se <- sqrt(diag(OI))\n  z_value <- result$par / se\n  df <- nrow(X) - ncol(X)\n  p_value <- 2 * pnorm(-1 * abs(z_value))\n\n  coef <- rbind(result$par, se, z_value, p_value)\n  colnames(coef) <- c(\"(Intercept)\", var_names)\n  rownames(coef) <- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n\n  b_hat <- result$par\n  predictions <- exp(X %*% b_hat)\n\n  if (predict) {\n    return(predictions)\n  } else {\n    return(t(coef))\n  }\n}\n```\n:::\n\n\nTesting poisson implementation with simulated data\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- sample(0:1, n, replace = T)\nlambda <- exp(2 + 0.5 * x1)\ny <- rpois(n, lambda)\nsim_data <- data.frame(y, x1)\nm1 <- glm(y ~ x1, family = poisson, data = sim_data)\nsummary(m1)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Estimate Std. Error   z value     Pr(>|z|)\n(Intercept) 1.9948197 0.04885319 40.832944 0.000000e+00\nx1          0.5035617 0.06556432  7.680423 1.585642e-14\n```\n:::\n\n```{.r .cell-code}\npoisson_function(fn_formula = \"y ~ x1\", data = sim_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Estimate Std. Error  z value      p value\n(Intercept) 1.9947730 0.04885433 40.83104 0.000000e+00\nx1          0.5036104 0.06556513  7.68107 1.577649e-14\n```\n:::\n\n```{.r .cell-code}\nggplot(sim_data) +\n  geom_histogram(aes(x = y, fill = factor(x1))) +\n  facet_wrap(~x1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-3-1.png){fig-align='left' width=8.5in}\n:::\n:::\n\n\nShow that our implementation of poisson regression can also make predictions\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nidx <- sample(1:n, 5)\np1 <- poisson_function(fn_formula = \"y ~ x1\", data = sim_data, predict = T)[idx]\np2 <- predict(m1, type = \"response\")[idx]\n\ncompare_predict_data <- data.frame(p1, p2)\ncolnames(compare_predict_data) <- c(\"Our implementation\", \"GLM\")\n\nkable(compare_predict_data, digits = 3, caption = \"Comparison of Poisson prediction\", booktabs = TRUE, valign = \"t\") |> kable_styling(latex_options = \"HOLD_position\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Comparison of Poisson prediction</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Our implementation </th>\n   <th style=\"text-align:right;\"> GLM </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:right;\"> 12.163 </td>\n   <td style=\"text-align:right;\"> 12.163 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 100 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 58 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 61 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 74 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n   <td style=\"text-align:right;\"> 7.351 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nTesting poisson implementation with `crabs` data\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# comparing coefficients with crabs data\ndata(crabs, package = \"glmbb\")\nsummary(glm(satell ~ width, family = poisson(link = \"log\"), data = crabs))$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error   z value     Pr(>|z|)\n(Intercept) -3.3047572 0.54224155 -6.094622 1.096964e-09\nwidth        0.1640451 0.01996535  8.216491 2.095450e-16\n```\n:::\n\n```{.r .cell-code}\n# a bit over-dispersed\nmean(crabs$satell)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.919075\n```\n:::\n\n```{.r .cell-code}\nvar(crabs$satell)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.912018\n```\n:::\n\n```{.r .cell-code}\npoisson_function(fn_formula = \"satell ~ width\", data = crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error   z value      p value\n(Intercept) -3.3041041 0.54211127 -6.094882 1.095184e-09\nwidth        0.1640204 0.01995812  8.218226 2.065351e-16\n```\n:::\n\n```{.r .cell-code}\nggplot(crabs) +\n  geom_histogram(aes(x = satell),\n    binwidth = 1,\n    fill = \"forestgreen\", color = \"gray\"\n  )\n```\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-5-1.png){fig-align='left' width=8.5in}\n:::\n:::\n\n\n**Interpretation of coefficients**\n\nA change in 1 unit of width has a multiplicative effect on the mean of $Y$. For a 1 unit increase in log(width), the estimated mean number of satellites increases by a factor of $e^{0.164} = 1.178$ when the log linear model is $log(\\mu_i) = -3.3 + 0.164 * width_i$.\n\n## Breaking Assumptions\n\n#### Independent observations\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- sample(0:5, n, replace = T)\nlambda <- exp(1.5 + 0.5 * x1)\ny <- rpois(n, lambda)\nsim_data <- data.frame(y, x1)\nmp <- glm(y ~ x1, data = sim_data, family = poisson)\nplot(mp, which = 1)\n```\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-6-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\nmp <- glm(satell ~ width, data = crabs, family = poisson)\nplot(mp, which = 1)\n```\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-6-2.png){fig-align='left' width=8.5in}\n:::\n:::\n\n\nCreating fake data that has good residuals vs crabs data which has a fitted line that is not at zero. It is easy to think about why the observations may not be independent for the crabs data, if a few are observed in clusters of units, or in certain ecologies.\n\n#### Distribution of counts follow a Poisson distribution\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nn <- 100\nx1 <- runif(n, 0, 10)\nx2 <- runif(n, -10, 0)\nlambda <- exp(1.5 + 0.5 * x1 + 0.5 * x2)\ny <- rpois(n, lambda)\ngood_data <- data.frame(y, x1, x2)\nlog.lambda <- log(poisson_function(fn_formula = \"y ~ x1 + x2\", data = good_data, predict = T))\nplot_data <- data.frame(log.lambda, x1, x2) |> gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-7-1.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\n# show non-linear data\nn <- 100\nx1 <- runif(n, 0, 10)\nx2 <- runif(n, -10, 0)\nlambda <- exp(0.5 * x1^2 + 0.5 * x1 * x2)\ny <- rpois(n, lambda)\nworse_data <- data.frame(y, x1, x2)\nlog.lambda <- log(poisson_function(fn_formula = \"y ~ x1 + x2\", data = worse_data, predict = T))\nplot_data <- data.frame(log.lambda, x1, x2) |> gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-7-2.png){fig-align='left' width=8.5in}\n:::\n\n```{.r .cell-code}\n# show for binary x1\nn <- 100\nx1 <- sample(0:1, n, replace = T)\nlambda <- exp(2 + 0.5 * x1)\ny <- rpois(n, lambda)\nsim_data <- data.frame(y, x1)\nlog.lambda <- log(poisson_function(fn_formula = \"y ~ x1\", data = sim_data, predict = T))\nplot_data <- data.frame(log.lambda, x1) |> gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](poisson_files/figure-html/unnamed-chunk-7-3.png){fig-align='left' width=8.5in}\n:::\n:::\n\n\nDoes the Poisson distribution predict well? We want to see a linear relationship between $log(\\lambda)$ and each predictor variable. This will only be visible for continuous predictor data.\n\n#### No overdispersion - the mean and variance of the distribution are equal\n\nOne of the main assumptions for Poisson regression is that the mean and variance are equal. When the variance is larger than the mean, there is overdispersion. This can be formally tested using the the overdispersion parameter.\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\ndata(crabs, package = \"glmbb\")\nM1 <- glm(satell ~ width, family = poisson(link = \"log\"), data = crabs)\nM2 <- glm.nb(satell ~ width, data = crabs)\nM3 <- pscl::zeroinfl(satell ~ width | width, data = crabs)\n# estimate overdispersion\nestimate_overdisp <- function(model_obj, data) {\n  z <- resid(model_obj, type = \"pearson\")\n  n <- nrow(data)\n  k <- length(coef(model_obj))\n  overdisp_ratio <- sum(z^2) / (n - k)\n  p_val <- pchisq(sum(z^2), (n - k))\n  return(cat(\"overdispersion ratio: \", overdisp_ratio, \"\\n\", \"p-value:\", p_val, \"\\n\"))\n}\nestimate_overdisp(M1, crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\noverdispersion ratio:  3.182205 \n p-value: 1 \n```\n:::\n\n```{.r .cell-code}\nestimate_overdisp(M2, crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\noverdispersion ratio:  0.8464955 \n p-value: 0.07176482 \n```\n:::\n\n```{.r .cell-code}\nestimate_overdisp(M3, crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\noverdispersion ratio:  1.349534 \n p-value: 0.9983357 \n```\n:::\n:::\n\n\nThe estimated overdispersion for the crabs data is 3.18, which is large, and has a p-value of 1, which indicates that the probability is essentially zero that a random variable from the distribution would be so large. When the negative binomial model is fitted, the crabs data has an estimated overdispersion of 0.85, with a smaller p-value. It is still overdispersed relative to a negative binomial distribution, but to a smaller scale than it was to a Poisson distribution.\n\n## Conclusion\n\nMeeting the assumptions for a Poisson regression, particularly for dispersion, is quite difficult, even when simulating data. It is unclear when the mean and variance of a distribution might happen to be naturally the same.\n",
    "supporting": [
      "poisson_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}