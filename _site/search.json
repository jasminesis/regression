[
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "setup",
    "section": "",
    "text": "library(knitr)\nopts_chunk$set(fig.width = 5, fig.height = 4, fig.align = \"left\", out.width = \"8.5in\")\n\nset.seed(123)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(alr4)\nlibrary(pscl)\nlibrary(glmbb) # for crabs data\nlibrary(kableExtra)\nlibrary(lmtest)"
  },
  {
    "objectID": "zipoisson.html",
    "href": "zipoisson.html",
    "title": "Zero-Inflated Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data, but if may not be the best model when there are excess zeroes in that data, which is when we may use Zero-inflated poisson regression instead. ZIP models have one parameter representing the probability of a structured zero, and another representing the Poisson mean. The ZIP distribution has the parameters \\(\\pi\\) and \\(\\lambda\\), denoted by \\(ZIP(\\pi, \\lambda)\\), with this probability mass function.\n\\[\\begin{equation}\n  P(X=k) =\n    \\begin{cases}\n      \\pi + (1-\\pi)(exp(-\\lambda)) & \\text{if $k = 0$}\\\\\n      (1-\\pi)exp(-\\lambda)\\frac{\\lambda^k}{k!} & \\text{if $k = 1, 2, 3, ...$}\\\\\n    \\end{cases}       \n\\end{equation}\\]\nThe figure below shows a zero-inflated Poisson model, where the zeros are either sampling zeros or structural zeros."
  },
  {
    "objectID": "zipoisson.html#introduction",
    "href": "zipoisson.html#introduction",
    "title": "Zero-Inflated Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data, but if may not be the best model when there are excess zeroes in that data, which is when we may use Zero-inflated poisson regression instead. ZIP models have one parameter representing the probability of a structured zero, and another representing the Poisson mean. The ZIP distribution has the parameters \\(\\pi\\) and \\(\\lambda\\), denoted by \\(ZIP(\\pi, \\lambda)\\), with this probability mass function.\n\\[\\begin{equation}\n  P(X=k) =\n    \\begin{cases}\n      \\pi + (1-\\pi)(exp(-\\lambda)) & \\text{if $k = 0$}\\\\\n      (1-\\pi)exp(-\\lambda)\\frac{\\lambda^k}{k!} & \\text{if $k = 1, 2, 3, ...$}\\\\\n    \\end{cases}       \n\\end{equation}\\]\nThe figure below shows a zero-inflated Poisson model, where the zeros are either sampling zeros or structural zeros."
  },
  {
    "objectID": "zipoisson.html#uses",
    "href": "zipoisson.html#uses",
    "title": "Zero-Inflated Poisson",
    "section": "Uses",
    "text": "Uses\nAn example of when ZIP-distributed count happens is when ecologists counting plants or animals get a zero when the species is absent at many sites, but get a Poisson distributed count when they are present. Another example is for estimating the the dental health of individuals, by counting how many dental cavities there are. Most people have 0 dental cavities as children, so this is a good use case for ZIP."
  },
  {
    "objectID": "zipoisson.html#assumptions",
    "href": "zipoisson.html#assumptions",
    "title": "Zero-Inflated Poisson",
    "section": "Assumptions",
    "text": "Assumptions\n\nIt follows the same assumptions for the Poisson regression for the counts generated by the Poisson process, and assumptions that apply for the logistic model that models the probability of being a zero."
  },
  {
    "objectID": "zipoisson.html#our-zero-inflated-poisson-regression-implementation",
    "href": "zipoisson.html#our-zero-inflated-poisson-regression-implementation",
    "title": "Zero-Inflated Poisson",
    "section": "Our Zero-inflated Poisson Regression Implementation",
    "text": "Our Zero-inflated Poisson Regression Implementation\n\nzippoisson_function &lt;- function(fn_formula, data) {\n  number_omitted &lt;- nrow(data) - nrow(na.omit(data))\n  data &lt;- na.omit(data)\n\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  covL &lt;- data[, vars[2]]\n  covp &lt;- data[, vars[3]]\n  n &lt;- nrow(data)\n  Y &lt;- matrix(data[, y_name], nrow = n, ncol = 1)\n\n  optim_zip &lt;- function(beta) {\n    lambda &lt;- exp(beta[1] + beta[2] * covL)\n    p &lt;- plogis(beta[3] + beta[4] * covp)\n    lik &lt;- p * (Y == 0) + (1 - p) * dpois(Y, lambda)\n    return(-sum(log(lik)))\n  }\n  result &lt;- optim(par = rep(0, 4), fn = optim_zip, hessian = T)\n  OI &lt;- solve(result$hessian)\n  se &lt;- sqrt(diag(OI))\n  z_value &lt;- result$par / se\n  p_value &lt;- 2 * pnorm(-1 * abs(z_value))\n\n  coef &lt;- rbind(result$par, se, z_value, p_value)\n\n  colnames(coef) &lt;- c(\"(Intercept)\", vars[2], \"(Intercept)\", vars[3])\n  rownames(coef) &lt;- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n  return(t(coef))\n}\n\nComparing performance\n\nn &lt;- 1000\ncovL &lt;- seq(0, 1, length.out = n)\ncovp &lt;- seq(0, 1, length.out = n)\ntrueMeans &lt;- exp(1.5 - 0.5 * covL)\nprobability &lt;- plogis(-0.5 + 2.5 * covp)\nU &lt;- runif(n, 0, 1)\ny &lt;- rpois(n, trueMeans)\ny[U &lt; probability] &lt;- 0\nzip_data &lt;- data.frame(y, covL, covp)\nhist(zip_data$y, main = \"Histogram of Zero-inflated Poisson data\", xlab = \"Count\")\n\n\n\n\n\n\n\n# comparing performance of our implementation with zeroinfl\nzippoisson_function(fn_formula = \"y ~ covL | covp\", data = zip_data)\n\n              Estimate Std. Error   z value       p value\n(Intercept)  1.5110398 0.04973986 30.378851 1.045285e-202\ncovL        -0.6505926 0.12418413 -5.238935  1.615060e-07\n(Intercept) -0.4266365 0.13620157 -3.132390  1.733893e-03\ncovp         2.4480016 0.26972049  9.076069  1.125674e-19\n\nsummary(pscl::zeroinfl(y ~ covL | covp))$coef\n\n$count\n              Estimate Std. Error   z value      Pr(&gt;|z|)\n(Intercept)  1.5111633 0.04973736 30.382862 9.252314e-203\ncovL        -0.6508453 0.12418346 -5.240998  1.597104e-07\n\n$zero\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.4263151  0.1362002 -3.130062 1.747691e-03\ncovp         2.4477580  0.2697245  9.075029 1.136467e-19"
  },
  {
    "objectID": "zipoisson.html#checking-assumptions",
    "href": "zipoisson.html#checking-assumptions",
    "title": "Zero-Inflated Poisson",
    "section": "Checking Assumptions",
    "text": "Checking Assumptions\n\nSuitability for ZIP or Poisson\nUsing the crabs data again, we will check the suitability for ZIP or Poisson with a likelihood ratio test.\n\nzip_model &lt;- pscl::zeroinfl(satell ~ width | width, data = crabs)\npois_model &lt;- glm(satell ~ width, family = poisson, data = crabs)\nlmtest::lrtest(zip_model, pois_model)\n\nWarning in modelUpdate(objects[[i - 1]], objects[[i]]): original model was of\nclass \"zeroinfl\", updated model is of class \"glm\"\n\n\nLikelihood ratio test\n\nModel 1: satell ~ width | width\nModel 2: satell ~ width\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 -364.82                         \n2   2 -461.59 -2 193.53  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf we set the significance level at 0.05, the likelihood ratio test shows that we should reject the null hypothesis, so the ZIP model offers an improvement in fit over the Poisson model, since the ZIP model has a log likelihood closer to zero.\n\npois_model &lt;- glm(y ~ covL + covp, data = zip_data)\nzip_model &lt;- pscl::zeroinfl(y ~ covL | covp, data = zip_data)\nlmtest::lrtest(zip_model, pois_model)\n\nWarning in modelUpdate(objects[[i - 1]], objects[[i]]): original model was of\nclass \"zeroinfl\", updated model is of class \"glm\"\n\n\nLikelihood ratio test\n\nModel 1: y ~ covL | covp\nModel 2: y ~ covL + covp\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 -1189.3                         \n2   3 -2060.6 -1 1742.6  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis likelihood ratio test of our own constructed dataset following a ZIP distribution also has a p-value of smaller than 0.05, and that the ZIP model has a log likelihood closer to zero, indicating better suitability for a ZIP model."
  },
  {
    "objectID": "zipoisson.html#conclusion",
    "href": "zipoisson.html#conclusion",
    "title": "Zero-Inflated Poisson",
    "section": "Conclusion",
    "text": "Conclusion\nZIP models provide a flexible framework by combining a Poisson distribution for positive counts with a logistic regression component to model the excess zeros. It is most appropriate to plot the data and see whether a dataset containing a count response variable is suited for Poisson or ZIP, and then conducting a likelihood ratio test to compare them."
  },
  {
    "objectID": "linear.html",
    "href": "linear.html",
    "title": "Linear",
    "section": "",
    "text": "Linear Regression is one of the simplest regressions out there. In predicting an outcome from various covariate(s), it creates the ‘best-fitting’ line to the data that we observe to create a model - in that it predicts values on the line when given specific values of the covariates."
  },
  {
    "objectID": "linear.html#introduction",
    "href": "linear.html#introduction",
    "title": "Linear",
    "section": "",
    "text": "Linear Regression is one of the simplest regressions out there. In predicting an outcome from various covariate(s), it creates the ‘best-fitting’ line to the data that we observe to create a model - in that it predicts values on the line when given specific values of the covariates."
  },
  {
    "objectID": "linear.html#uses",
    "href": "linear.html#uses",
    "title": "Linear",
    "section": "Uses",
    "text": "Uses\nLinear Regression is used across various fields. It is a model which has high bias and low variance. This means that even though it may not fit the data observed in the most optimal way (in that it may not be able to capture complexities in the data), it is not that sensitive to changes in the training data, which can make it more stable when dealing with small fluctuations or noise in the data set. Linear Regression can be used for predicting continuous, categorical, and even binary outcomes (as is often done in Causal Inference)."
  },
  {
    "objectID": "linear.html#assumptions",
    "href": "linear.html#assumptions",
    "title": "Linear",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe predictors and the outcome are linearly related to one another\nThe errors are normally distributed and are independent of one another\nThe errors are homoscedastic"
  },
  {
    "objectID": "linear.html#our-linear-regression-implementation",
    "href": "linear.html#our-linear-regression-implementation",
    "title": "Linear",
    "section": "Our Linear Regression Implementation",
    "text": "Our Linear Regression Implementation\nOur Linear Regression implementation: (Note that we use bootstrapping to estimate standard errors)\n\nlinear_regression &lt;- function(data, ..., y) {\n  x_parameters &lt;- c(...)\n  n &lt;- nrow(data)\n  # defining the predictor matrix\n  X &lt;-\n    matrix(c(rep(1, n), x_parameters),\n      nrow = n,\n      ncol = ncol(data)\n    )\n  # defining the outcome matrix\n  Y &lt;- matrix(y, nrow = n, ncol = 1)\n  # solving for the beta coefficients\n  beta &lt;- solve(t(X) %*% X) %*% t(X) %*% Y\n  # creating a vector 'estimate' for the beta coefficients\n  estimate &lt;- c()\n  for (i in 1:ncol(X)) {\n    estimate[i] &lt;- beta[i]\n  }\n  # bootstrapping to estimate the standard errors\n  num_bootstraps &lt;- 10000\n  bootstrap_betas &lt;-\n    matrix(0, nrow = num_bootstraps, ncol = ncol(data))\n  for (i in 1:num_bootstraps) {\n    sample_indices &lt;- sample(nrow(data), replace = TRUE)\n    bootstrap_data &lt;- data[sample_indices, ]\n    bootstrap_X &lt;-\n      as.matrix(cbind(1, bootstrap_data[, 1:(ncol(bootstrap_data) - 1)]))\n    bootstrap_Y &lt;- as.matrix(bootstrap_data$y, ncol = 1)\n    bootstrap_beta &lt;-\n      solve(t(bootstrap_X) %*% bootstrap_X) %*% t(bootstrap_X) %*% bootstrap_Y\n    bootstrap_betas[i, ] &lt;- bootstrap_beta\n  }\n  # finding the standard deviation of the bootstrapped betas to find the\n  # standard error of the coefficients\n  se &lt;- c()\n  for (i in 1:ncol(X)) {\n    se[i] &lt;- apply(bootstrap_betas, 2, sd)[i]\n  }\n  # calculating the t-statistic\n  t &lt;- estimate / se\n  # defining the degrees of freedom\n  df &lt;- nrow(X) - ncol(X)\n  # calculating the p-value\n  p &lt;- 2 * pt(t, df, lower = F)\n  # calculating the residuals\n  resid &lt;- Y - X %*% beta\n  residual &lt;- sqrt(mean((resid)^2))\n  # defining the row names of the output data frame\n  rownames &lt;- c()\n  for (i in 1:((ncol(X)) - 1)) {\n    rownames[i] &lt;- i\n  }\n  test &lt;- list(\n    plot(resid, main = \"Residual Plot to test homoscedasticity of errors\", ylim = c(-10, 10)),\n    qqnorm(resid, main = \"Q-Q plot to test normality of errors\"),\n    pairs(data, main = \"Assessing Linearity of\\n Predictors with Outcome\")\n  )\n  impl &lt;- data.frame(\n    Estimate = estimate,\n    Std.Error = se,\n    t.value = t,\n    p.value = p,\n    Residual = c(residual, rep(NA, ncol(X) - 1)),\n    DegOfFreedom = c(df, rep(NA, ncol(X) - 1)),\n    row.names = c(\"(Intercept)\", paste0(rep(\"x\", ncol(\n      X\n    ) - 1), rownames))\n  )\n  # returning a data frame akin to the lm output\n  return(list(test, impl))\n}\n\nCreating a test data set which meets all Linear Regression assumptions to check if our function works.\n\ntest_linear_regression_data &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- rnorm(100, mean = 0, sd = 1) # errors are homoscedastic\ntest_linear_regression_data$y &lt;-\n  2 * test_linear_regression_data$x1 +\n  0.2 * test_linear_regression_data$x2 + error\n\nplot(test_linear_regression_data$x1, test_linear_regression_data$y,\n  xlab = \"x1\", ylab = \"y\",\n  main = \"Outcome is linear to x1\"\n)\n\n\n\n\n\n\n\nplot(test_linear_regression_data$x2, test_linear_regression_data$y,\n  xlab = \"x2\", ylab = \"y\",\n  main = \"Outcome is linear to x2 (it is not apparent in this plot but our data structure captures this relationship)\", cex.main = 0.6\n)\n\n\n\n\n\n\n\nplot(density(error), main = \"Errors are normally distributed with mean 0\")\n\n\n\n\n\n\n\nplot(error,\n  ylab = \"residuals\", main = \"Residuals are homoscedastic\", ylim = c(-3, 3)\n)"
  },
  {
    "objectID": "linear.html#testing-assumptions-for-linear-regression",
    "href": "linear.html#testing-assumptions-for-linear-regression",
    "title": "Linear",
    "section": "Testing Assumptions for Linear Regression",
    "text": "Testing Assumptions for Linear Regression\n\nour_implementation &lt;- linear_regression(\n  test_linear_regression_data,\n  test_linear_regression_data$x1,\n  test_linear_regression_data$x2,\n  y = test_linear_regression_data$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation\n\n             Estimate  Std.Error   t.value      p.value  Residual DegOfFreedom\n(Intercept) 0.4679943 0.31344739  1.493055 1.386684e-01 0.9369198           97\nx1          1.9334142 0.05792076 33.380331 5.582525e-55        NA           NA\nx2          0.2119056 0.05038448  4.205772 5.802633e-05        NA           NA\n\n\nComparing our output to R’s output.\n\nr_implementation &lt;-\n  summary(lm(y ~ x1 + x2, data = test_linear_regression_data))\nr_implementation\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = test_linear_regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8730 -0.6607 -0.1245  0.6214  2.0798 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.46799    0.28753   1.628    0.107    \nx1           1.93341    0.05243  36.873  &lt; 2e-16 ***\nx2           0.21191    0.04950   4.281 4.37e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9513 on 97 degrees of freedom\nMultiple R-squared:  0.9337,    Adjusted R-squared:  0.9323 \nF-statistic: 682.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nWe note that the results are similar.\nWe followed all assumptions of Linear Regression in regressing y on x1 and x2 using the test_linear_regression_data data set. We will compare the residual of this regression to that of all the others where assumptions will be broken.\nThe residual for where all assumptions are met:\n\nour_implementation$Residual[1] # a small residual here\n\n[1] 0.9369198"
  },
  {
    "objectID": "linear.html#breaking-assumptions",
    "href": "linear.html#breaking-assumptions",
    "title": "Linear",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nBreaking the assumption of the predictors and outcome following a linear relationship\nCreating a data set where, if we apply linear regression, this assumption will be broken.\n\ntest_linear_regression_data_not_linear &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- rnorm(100, mean = 0, sd = 1)\ntest_linear_regression_data_not_linear$y &lt;-\n  2 * test_linear_regression_data_not_linear$x1^2 + 0.2 *\n    test_linear_regression_data_not_linear$x2^2 + error\n\nplot(test_linear_regression_data_not_linear$x1, test_linear_regression_data_not_linear$y,\n  xlab = \"x1\", ylab = \"y\",\n  main = \"Outcome is not linear to x1\"\n)\n\n\n\n\n\n\n\nplot(test_linear_regression_data_not_linear$x2, test_linear_regression_data_not_linear$y,\n  xlab = \"x2\", ylab = \"y\",\n  main = \"Outcome is not linear to x2\"\n)\n\n\n\n\n\n\n\n\nUsing our implementation of Linear Regression to fit the model.\n\nour_implementation_not_linear &lt;- linear_regression(\n  test_linear_regression_data_not_linear,\n  test_linear_regression_data_not_linear$x1,\n  test_linear_regression_data_not_linear$x2,\n  y = test_linear_regression_data_not_linear$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation_not_linear$Residual[1] # a higher residual here\n\n[1] 10.22817\n\n\nWe note that linear regression is not performing as well in this case.\n\n\nBreaking the assumption of the errors being normally distributed\nCreating a data set where, if we apply linear regression, this assumption will be broken.\n\ntest_linear_regression_data_not_normally_dist &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- runif(100, min = 0, max = 5)\ntest_linear_regression_data_not_normally_dist$y &lt;-\n  2 * test_linear_regression_data_not_normally_dist$x1 + 0.2 *\n    test_linear_regression_data_not_normally_dist$x2 + error\n\nplot(density(error), main = \"Errors are not normally distributed\")\n\n\n\n\n\n\n\n\nUsing our implementation of lm to fit the model.\n\nour_implementation_not_normally_dist &lt;- linear_regression(\n  test_linear_regression_data_not_normally_dist,\n  test_linear_regression_data_not_normally_dist$x1,\n  test_linear_regression_data_not_normally_dist$x2,\n  y = test_linear_regression_data_not_normally_dist$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation_not_normally_dist$Residual[1] # a higher residual here\n\n[1] 1.414274\n\n\nWe note that linear regression is not performing as well in this case.\n\n\nBreaking the assumption of the errors being homoscedastic\nCreating a data set where, if we apply linear regression, this assumption will be broken.\n\ntest_linear_regression_data_not_homoscedastic &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- c(\n  rnorm(50, mean = 0, sd = 1),\n  rnorm(50, mean = 0, sd = 10)\n)\ntest_linear_regression_data_not_homoscedastic$y &lt;-\n  2 * test_linear_regression_data_not_homoscedastic$x1 + 0.2 *\n    test_linear_regression_data_not_homoscedastic$x2 + error\n\nplot(error,\n  ylab = \"error\", main = \"Residuals are not homoscedastic\", ylim = c(-20, 20)\n)\n\n\n\n\n\n\n\n\nUsing our implementation of lm to fit the model.\n\nour_implementation_not_homoscedastic &lt;- linear_regression(\n  test_linear_regression_data_not_homoscedastic,\n  test_linear_regression_data_not_homoscedastic$x1,\n  test_linear_regression_data_not_homoscedastic$x2,\n  y = test_linear_regression_data_not_homoscedastic$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation_not_homoscedastic$Residual[1] # a higher residual here\n\n[1] 6.419781\n\n\nWe note that linear regression is not performing as well in this case."
  },
  {
    "objectID": "linear.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "href": "linear.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "title": "Linear",
    "section": "Comparing residuals when all assumptions were met versus not",
    "text": "Comparing residuals when all assumptions were met versus not\n\nresidual_comparison &lt;-\n  t(\n    data.frame(\n      resid_all_assumptions_met = our_implementation$Residual[1],\n      resid_not_linear = our_implementation_not_linear$Residual[1],\n      resid_not_normally_dist = our_implementation_not_normally_dist$Residual[1],\n      resid_not_homoscedastic = our_implementation_not_homoscedastic$Residual[1]\n    )\n  )\nrow.names(residual_comparison) &lt;- c(\n  \"All assumptions met\",\n  \"Linearity assumption violated\",\n  \"Normality assumption violated\",\n  \"Homoscedasticity assumption violated\"\n)\ncolnames(residual_comparison) &lt;- \"Residuals\"\nresidual_comparison\n\n                                      Residuals\nAll assumptions met                   0.9369198\nLinearity assumption violated        10.2281685\nNormality assumption violated         1.4142737\nHomoscedasticity assumption violated  6.4197814"
  },
  {
    "objectID": "linear.html#conclusion",
    "href": "linear.html#conclusion",
    "title": "Linear",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation of Linear Regression where all assumptions are met performs the best; i.e. it gives us predictions which are closest to the true outcome values. From the residual comparison, we also note that applying linear regression to data that aren’t linear can be especially worrisome."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DIY Regression",
    "section": "",
    "text": "DIY Regression project for NYU Stats Consulting - Fall 2023\nBy Jasmine Siswandjo and Saumya Seth\n\nLinear regression\nProbit regression\nNegative Binomial regression\nLogistic regression\nPoisson regression\n\nZero-inflated Poisson regression\n\nFor each of the 6 regression types, we implemented our own functions without using in-built regression packages in R. We estimated coefficients of the predictors, estimated their standard errors, and calculated the p-values of said models.\nWe also explored and checked the assumptions of each model, and discussed the implications of breaking those assumptions.\nAttribution\n\nFavicon from Freepik"
  },
  {
    "objectID": "poisson.html",
    "href": "poisson.html",
    "title": "Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data. We use Poisson distribution to model the expected value of \\(Y\\), which is denoted by \\(E(Y) = \\mu\\). The identity link is the log link, so the Poisson regression model for counts is \\(log(\\mu) = \\alpha + \\beta x\\). The Poisson distribution with parameter \\(\\lambda\\), \\(Poi(\\lambda)\\) has the probability mass function\n\\[\nP(X=k) = exp(-\\lambda)\\frac{\\lambda^k}{k!}, k=0,1,2,3,...\n\\]"
  },
  {
    "objectID": "poisson.html#introduction",
    "href": "poisson.html#introduction",
    "title": "Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data. We use Poisson distribution to model the expected value of \\(Y\\), which is denoted by \\(E(Y) = \\mu\\). The identity link is the log link, so the Poisson regression model for counts is \\(log(\\mu) = \\alpha + \\beta x\\). The Poisson distribution with parameter \\(\\lambda\\), \\(Poi(\\lambda)\\) has the probability mass function\n\\[\nP(X=k) = exp(-\\lambda)\\frac{\\lambda^k}{k!}, k=0,1,2,3,...\n\\]"
  },
  {
    "objectID": "poisson.html#uses",
    "href": "poisson.html#uses",
    "title": "Poisson",
    "section": "Uses",
    "text": "Uses\nPoisson regression can be used for count data, such as number of asthmatic attacks in one year based on the number of hospital admissions and systolic blood pressure. When the predictor variables are continuous, poisson regression ensures that the outcome variable is positive, compared to a linear regression which might predict negative counts. Another use case for Poisson regression is when the number of cases is small relative to the number of no events, such as when the number of deaths due to COVID-19 are small relative to the total population size. Logistic regression is more useful when we have data on both the binary outcomes (e.g. death and non-deaths)."
  },
  {
    "objectID": "poisson.html#assumptions",
    "href": "poisson.html#assumptions",
    "title": "Poisson",
    "section": "Assumptions",
    "text": "Assumptions\n\noutcome variable must be count data\nIndependent observations\nDistribution of counts follow a Poisson distribution\nNo overdispersion - the mean and variance of the distribution are equal. If the variance is greater than the mean, negative binomial regression may be more appropriate"
  },
  {
    "objectID": "poisson.html#our-poisson-regression-implementation",
    "href": "poisson.html#our-poisson-regression-implementation",
    "title": "Poisson",
    "section": "Our Poisson Regression Implementation",
    "text": "Our Poisson Regression Implementation\n\npoisson_function &lt;- function(fn_formula, data, predict = F) {\n  number_omitted &lt;- nrow(data) - nrow(na.omit(data))\n  data &lt;- na.omit(data)\n\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  x_name &lt;- vars[2:length(vars)]\n  n &lt;- nrow(data)\n  Y &lt;- matrix(data[, y_name], nrow = n, ncol = 1)\n  X &lt;- matrix(cbind(rep(1, n)))\n\n  # take in categorical data\n  var_names &lt;- vector(\"character\")\n  for (i in x_name) {\n    if (suppressWarnings(all(!is.na(as.numeric(as.character(data[, i])))))) {\n      X &lt;- cbind(X, as.numeric(as.character(data[, i])))\n      var_names &lt;- c(var_names, i)\n    } else {\n      categories &lt;- sort(unique(data[, i]))\n      for (j in categories[2:length(categories)]) {\n        new_col_name &lt;- paste0(i, j)\n        new_col &lt;- ifelse(data[, i] == j, 1, 0)\n        X &lt;- cbind(X, new_col)\n        var_names &lt;- c(var_names, new_col_name)\n      }\n    }\n  }\n  optim_poisson &lt;- function(beta, X, Y) {\n    beta &lt;- as.matrix(beta, nrow = 4)\n    beta_x &lt;- X %*% beta\n    loglikelihood &lt;- -sum(Y * beta_x - exp(beta_x))\n    return(loglikelihood)\n  }\n  result &lt;- optim(par = rep(0, ncol(X)), fn = optim_poisson, X = X, Y = Y, hessian = T)\n  OI &lt;- solve(result$hessian)\n  se &lt;- sqrt(diag(OI))\n  z_value &lt;- result$par / se\n  df &lt;- nrow(X) - ncol(X)\n  p_value &lt;- 2 * pnorm(-1 * abs(z_value))\n\n  coef &lt;- rbind(result$par, se, z_value, p_value)\n  colnames(coef) &lt;- c(\"(Intercept)\", var_names)\n  rownames(coef) &lt;- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n\n  b_hat &lt;- result$par\n  predictions &lt;- exp(X %*% b_hat)\n\n  if (predict) {\n    return(predictions)\n  } else {\n    return(t(coef))\n  }\n}\n\nTesting poisson implementation with simulated data\n\nn &lt;- 100\nx1 &lt;- sample(0:1, n, replace = T)\nlambda &lt;- exp(2 + 0.5 * x1)\ny &lt;- rpois(n, lambda)\nsim_data &lt;- data.frame(y, x1)\nm1 &lt;- glm(y ~ x1, family = poisson, data = sim_data)\nsummary(m1)$coef\n\n             Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) 1.9948197 0.04885319 40.832944 0.000000e+00\nx1          0.5035617 0.06556432  7.680423 1.585642e-14\n\npoisson_function(fn_formula = \"y ~ x1\", data = sim_data)\n\n             Estimate Std. Error  z value      p value\n(Intercept) 1.9947730 0.04885433 40.83104 0.000000e+00\nx1          0.5036104 0.06556513  7.68107 1.577649e-14\n\nggplot(sim_data) +\n  geom_histogram(aes(x = y, fill = factor(x1))) +\n  facet_wrap(~x1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nShow that our implementation of poisson regression can also make predictions\n\nidx &lt;- sample(1:n, 5)\np1 &lt;- poisson_function(fn_formula = \"y ~ x1\", data = sim_data, predict = T)[idx]\np2 &lt;- predict(m1, type = \"response\")[idx]\n\ncompare_predict_data &lt;- data.frame(p1, p2)\ncolnames(compare_predict_data) &lt;- c(\"Our implementation\", \"GLM\")\n\nkable(compare_predict_data, digits = 3, caption = \"Comparison of Poisson prediction\", booktabs = TRUE, valign = \"t\") |&gt; kable_styling(latex_options = \"HOLD_position\")\n\n\nComparison of Poisson prediction\n\n\n\nOur implementation\nGLM\n\n\n\n\n7\n12.163\n12.163\n\n\n100\n7.351\n7.351\n\n\n58\n7.351\n7.351\n\n\n61\n7.351\n7.351\n\n\n74\n7.351\n7.351\n\n\n\n\n\n\n\nTesting poisson implementation with crabs data\n\n# comparing coefficients with crabs data\ndata(crabs, package = \"glmbb\")\nsummary(glm(satell ~ width, family = poisson(link = \"log\"), data = crabs))$coef\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -3.3047572 0.54224155 -6.094622 1.096964e-09\nwidth        0.1640451 0.01996535  8.216491 2.095450e-16\n\n# a bit over-dispersed\nmean(crabs$satell)\n\n[1] 2.919075\n\nvar(crabs$satell)\n\n[1] 9.912018\n\npoisson_function(fn_formula = \"satell ~ width\", data = crabs)\n\n              Estimate Std. Error   z value      p value\n(Intercept) -3.3041041 0.54211127 -6.094882 1.095184e-09\nwidth        0.1640204 0.01995812  8.218226 2.065351e-16\n\nggplot(crabs) +\n  geom_histogram(aes(x = satell),\n    binwidth = 1,\n    fill = \"forestgreen\", color = \"gray\"\n  )\n\n\n\n\n\n\n\n\nInterpretation of coefficients\nA change in 1 unit of width has a multiplicative effect on the mean of \\(Y\\). For a 1 unit increase in log(width), the estimated mean number of satellites increases by a factor of \\(e^{0.164} = 1.178\\) when the log linear model is \\(log(\\mu_i) = -3.3 + 0.164 * width_i\\)."
  },
  {
    "objectID": "poisson.html#breaking-assumptions",
    "href": "poisson.html#breaking-assumptions",
    "title": "Poisson",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nIndependent observations\n\nn &lt;- 100\nx1 &lt;- sample(0:5, n, replace = T)\nlambda &lt;- exp(1.5 + 0.5 * x1)\ny &lt;- rpois(n, lambda)\nsim_data &lt;- data.frame(y, x1)\nmp &lt;- glm(y ~ x1, data = sim_data, family = poisson)\nplot(mp, which = 1)\n\n\n\n\n\n\n\nmp &lt;- glm(satell ~ width, data = crabs, family = poisson)\nplot(mp, which = 1)\n\n\n\n\n\n\n\n\nCreating fake data that has good residuals vs crabs data which has a fitted line that is not at zero. It is easy to think about why the observations may not be independent for the crabs data, if a few are observed in clusters of units, or in certain ecologies.\n\n\nDistribution of counts follow a Poisson distribution\n\nn &lt;- 100\nx1 &lt;- runif(n, 0, 10)\nx2 &lt;- runif(n, -10, 0)\nlambda &lt;- exp(1.5 + 0.5 * x1 + 0.5 * x2)\ny &lt;- rpois(n, lambda)\ngood_data &lt;- data.frame(y, x1, x2)\nlog.lambda &lt;- log(poisson_function(fn_formula = \"y ~ x1 + x2\", data = good_data, predict = T))\nplot_data &lt;- data.frame(log.lambda, x1, x2) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# show non-linear data\nn &lt;- 100\nx1 &lt;- runif(n, 0, 10)\nx2 &lt;- runif(n, -10, 0)\nlambda &lt;- exp(0.5 * x1^2 + 0.5 * x1 * x2)\ny &lt;- rpois(n, lambda)\nworse_data &lt;- data.frame(y, x1, x2)\nlog.lambda &lt;- log(poisson_function(fn_formula = \"y ~ x1 + x2\", data = worse_data, predict = T))\nplot_data &lt;- data.frame(log.lambda, x1, x2) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# show for binary x1\nn &lt;- 100\nx1 &lt;- sample(0:1, n, replace = T)\nlambda &lt;- exp(2 + 0.5 * x1)\ny &lt;- rpois(n, lambda)\nsim_data &lt;- data.frame(y, x1)\nlog.lambda &lt;- log(poisson_function(fn_formula = \"y ~ x1\", data = sim_data, predict = T))\nplot_data &lt;- data.frame(log.lambda, x1) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDoes the Poisson distribution predict well? We want to see a linear relationship between \\(log(\\lambda)\\) and each predictor variable. This will only be visible for continuous predictor data.\n\n\nNo overdispersion - the mean and variance of the distribution are equal\nOne of the main assumptions for Poisson regression is that the mean and variance are equal. When the variance is larger than the mean, there is overdispersion. This can be formally tested using the the overdispersion parameter.\n\ndata(crabs, package = \"glmbb\")\nM1 &lt;- glm(satell ~ width, family = poisson(link = \"log\"), data = crabs)\nM2 &lt;- glm.nb(satell ~ width, data = crabs)\nM3 &lt;- pscl::zeroinfl(satell ~ width | width, data = crabs)\n# estimate overdispersion\nestimate_overdisp &lt;- function(model_obj, data) {\n  z &lt;- resid(model_obj, type = \"pearson\")\n  n &lt;- nrow(data)\n  k &lt;- length(coef(model_obj))\n  overdisp_ratio &lt;- sum(z^2) / (n - k)\n  p_val &lt;- pchisq(sum(z^2), (n - k))\n  return(cat(\"overdispersion ratio: \", overdisp_ratio, \"\\n\", \"p-value:\", p_val, \"\\n\"))\n}\nestimate_overdisp(M1, crabs)\n\noverdispersion ratio:  3.182205 \n p-value: 1 \n\nestimate_overdisp(M2, crabs)\n\noverdispersion ratio:  0.8464955 \n p-value: 0.07176482 \n\nestimate_overdisp(M3, crabs)\n\noverdispersion ratio:  1.349534 \n p-value: 0.9983357 \n\n\nThe estimated overdispersion for the crabs data is 3.18, which is large, and has a p-value of 1, which indicates that the probability is essentially zero that a random variable from the distribution would be so large. When the negative binomial model is fitted, the crabs data has an estimated overdispersion of 0.85, with a smaller p-value. It is still overdispersed relative to a negative binomial distribution, but to a smaller scale than it was to a Poisson distribution."
  },
  {
    "objectID": "poisson.html#conclusion",
    "href": "poisson.html#conclusion",
    "title": "Poisson",
    "section": "Conclusion",
    "text": "Conclusion\nMeeting the assumptions for a Poisson regression, particularly for dispersion, is quite difficult, even when simulating data. It is unclear when the mean and variance of a distribution might happen to be naturally the same."
  },
  {
    "objectID": "logistic.html",
    "href": "logistic.html",
    "title": "Logistic",
    "section": "",
    "text": "Logistic regression is used when the outcome variable is discrete and binary, which is called classification. Multinomial logistic regression can classify observations into more than two categories, but we are only doing simple logistic regression here, with two categories. We use the inverse logit function to model the probability that \\(Y_i = 1\\).\n\\[\nlogit^{-1}(x)=\\frac{e^x}{1+e^x} \\\\\nPr(y_i=1) = logit^{-1}(X_i\\beta)\n\\]plogis is the invlogit function."
  },
  {
    "objectID": "logistic.html#introduction",
    "href": "logistic.html#introduction",
    "title": "Logistic",
    "section": "",
    "text": "Logistic regression is used when the outcome variable is discrete and binary, which is called classification. Multinomial logistic regression can classify observations into more than two categories, but we are only doing simple logistic regression here, with two categories. We use the inverse logit function to model the probability that \\(Y_i = 1\\).\n\\[\nlogit^{-1}(x)=\\frac{e^x}{1+e^x} \\\\\nPr(y_i=1) = logit^{-1}(X_i\\beta)\n\\]plogis is the invlogit function."
  },
  {
    "objectID": "logistic.html#uses",
    "href": "logistic.html#uses",
    "title": "Logistic",
    "section": "Uses",
    "text": "Uses\nLogistic regression is good for when covariates are continuous, as the outcome variables are bounded between 0 and 1, through the logit link."
  },
  {
    "objectID": "logistic.html#assumptions",
    "href": "logistic.html#assumptions",
    "title": "Logistic",
    "section": "Assumptions",
    "text": "Assumptions\n\nFor binary logistic regression, that outcome variables are binary\nIndependence of errors\nLinear relationship between the outcome variable and log odds of the predictor variables\nNo multicollinearity"
  },
  {
    "objectID": "logistic.html#our-logistic-regression-implementation",
    "href": "logistic.html#our-logistic-regression-implementation",
    "title": "Logistic",
    "section": "Our Logistic Regression Implementation",
    "text": "Our Logistic Regression Implementation\n\nlibrary(alr4)\n# invlogit &lt;- plogis\n\nlogistic_function &lt;- function(fn_formula, data, predict = F) {\n  number_omitted &lt;- nrow(data) - nrow(na.omit(data))\n  data &lt;- na.omit(data)\n\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  x_name &lt;- vars[2:length(vars)]\n  n &lt;- nrow(data)\n  Y &lt;- matrix(data[, y_name], nrow = n, ncol = 1)\n  X &lt;- matrix(cbind(rep(1, n)))\n\n  # take in categorical data\n  var_names &lt;- vector(\"character\")\n  for (i in x_name) {\n    if (suppressWarnings(all(!is.na(as.numeric(as.character(data[, i])))))) {\n      X &lt;- cbind(X, as.numeric(as.character(data[, i])))\n      var_names &lt;- c(var_names, i)\n    } else {\n      categories &lt;- sort(unique(data[, i]))\n      for (j in categories[2:length(categories)]) {\n        new_col_name &lt;- paste0(i, j)\n        new_col &lt;- ifelse(data[, i] == j, 1, 0)\n        X &lt;- cbind(X, new_col)\n        var_names &lt;- c(var_names, new_col_name)\n      }\n    }\n  }\n  optim_logistic &lt;- function(beta, X, Y) {\n    beta &lt;- as.matrix(beta, nrow = 4)\n    pi &lt;- plogis(X %*% beta)\n    loglikelihood &lt;- -sum(Y * log(pi) + (1 - Y) * log(1 - pi))\n    return(loglikelihood)\n  }\n  result &lt;- optim(par = rep(0, ncol(X)), fn = optim_logistic, X = X, Y = Y, hessian = T)\n  OI &lt;- solve(result$hessian)\n  se &lt;- sqrt(diag(OI))\n  t_statistic &lt;- result$par / se\n  df &lt;- nrow(X) - ncol(X)\n  p_value &lt;- 2 * pnorm(-1 * abs(t_statistic))\n  # https://stats.stackexchange.com/questions/52475/how-are-the-p-values-of-the-glm-in-r-calculated\n\n  coef &lt;- rbind(result$par, se, t_statistic, p_value)\n  colnames(coef) &lt;- c(\"(Intercept)\", var_names)\n  rownames(coef) &lt;- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n  coef &lt;- t(coef)\n\n  b_hat &lt;- result$par\n  predictions &lt;- plogis(X %*% b_hat)\n\n  if (predict) {\n    return(predictions)\n  } else {\n    return(coef)\n  }\n}\n\nCreating testing data set with a single predictor variable to compare our implementation with glm logistic function\n\n# create fake data\nx1 &lt;- rnorm(100, 2, 1)\nprob &lt;- plogis(-1 + 0.5 * x1)\ny &lt;- rbinom(100, 1, prob)\nsim_data &lt;- data.frame(y, x1)\n\n# compare DIY logistic function with glm\nfit_sim_data_1 &lt;- glm(y ~ x1, data = sim_data, family = binomial)\nsummary(fit_sim_data_1)$coef\n\n              Estimate Std. Error   z value   Pr(&gt;|z|)\n(Intercept) -0.7456721  0.5316508 -1.402560 0.16074811\nx1           0.5410003  0.2427422  2.228703 0.02583366\n\nlogistic_function(fn_formula = \"y ~ x1\", data = sim_data)\n\n              Estimate Std. Error   z value    p value\n(Intercept) -0.7459709  0.5316604 -1.403097 0.16058801\nx1           0.5410940  0.2427464  2.229051 0.02581053\n\n# checking for linear relationship\nplot(sim_data$x1, prob,\n  main = \"The log odds of y and x1 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\n# check for correlation of residuals vs fit\nplot(fit_sim_data_1, which = 1)\n\n\n\n\n\n\n\n\nCreating testing data set with multiple covariates to compare our implementation with glm logistic function\n\n# create fake data with multiple x's\nx1 &lt;- rnorm(100, 2, 1)\nx2 &lt;- rnorm(100, 4, 1)\nx3 &lt;- rnorm(100, 6, 1)\nprob &lt;- plogis(-1 + x1 + x2 - 0.5 * x3)\ny &lt;- rbinom(100, 1, prob)\nsim_data &lt;- data.frame(y, x1, x2, x3)\n\n# compare DIY logistic function with glm\nfit_sim_data &lt;- glm(y ~ x1 + x2 + x3, data = sim_data, family = binomial)\nsummary(fit_sim_data)$coef\n\n              Estimate Std. Error    z value    Pr(&gt;|z|)\n(Intercept)  2.4011218  2.4617714  0.9753634 0.329380012\nx1           1.3097873  0.4646174  2.8190663 0.004816356\nx2           0.9528707  0.3591008  2.6534911 0.007966387\nx3          -1.1133007  0.3837826 -2.9008631 0.003721364\n\nlogistic_function(fn_formula = \"y ~ x1 + x2 + x3\", data = sim_data)\n\n              Estimate Std. Error    z value     p value\n(Intercept)  2.4003220  2.4618335  0.9750139 0.329553343\nx1           1.3102691  0.4646817  2.8197132 0.004806659\nx2           0.9530523  0.3591195  2.6538587 0.007957715\nx3          -1.1134496  0.3838115 -2.9010321 0.003719358\n\n\nUsing the alr4 Donner data to test categorical data, and compare our implementation with glm logistic function\n\nDonner$survived &lt;- Donner$y == \"survived\"\nfit_Donner &lt;- glm(survived ~ age + sex + status, data = Donner, family = \"binomial\")\nsummary(fit_Donner)$coef\n\n                Estimate   Std. Error      z value    Pr(&gt;|z|)\n(Intercept)    1.4873491 4.926432e-01  3.019120666 0.002535095\nage           -0.0281043 1.504262e-02 -1.868311545 0.061718658\nsexMale       -0.7279889 5.172218e-01 -1.407498622 0.159279585\nstatusHired   -0.5985928 6.281956e-01 -0.952876467 0.340652665\nstatusSingle -17.4555740 1.765537e+03 -0.009886838 0.992111573\n\nlogistic_function(fn_formula = \"survived ~ age + sex + status\", data = Donner)\n\n                Estimate  Std. Error    z value     p value\n(Intercept)   1.50395496  0.49431184  3.0425226 0.002346042\nage          -0.02838637  0.01507534 -1.8829672 0.059704810\nsexMale      -0.74855738  0.51805480 -1.4449386 0.148475138\nstatusHired  -0.58665853  0.62833280 -0.9336748 0.350471646\nstatusSingle -6.48117449 12.14886686 -0.5334798 0.593701523\n\n\nInterpretation of the coefficients\nA 1-unit difference in age corresponds to -0.02 in the logit probability of having survived in the Donner party, or a multiplicative change of \\(e^{-0.0283}=0.972\\) in the odds of surviving.\n\nggplot(Donner) +\n  geom_jitter(aes(x = age, y = survived, color = survived)) +\n  facet_wrap(vars(status)) +\n  ggtitle(\"Younger people generally had a higher chance of surviving\")\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nShow that our implementation of logistic regression can also make predictions\n\nidx &lt;- sample(1:nrow(Donner), 5)\np1 &lt;- logistic_function(fn_formula = \"survived ~ age + sex + status\", data = Donner, predict = T)[idx, ]\np2 &lt;- predict(fit_Donner, type = \"response\")[idx]\ncompare_predict_data &lt;- data.frame(p1, p2)\ncolnames(compare_predict_data) &lt;- c(\"Our implementation\", \"GLM\")\n\nkable(compare_predict_data, digits = 3, caption = \"Comparison of logistic prediction\", booktabs = TRUE, valign = \"t\") |&gt; kable_styling(latex_options = \"HOLD_position\")\n\n\nComparison of logistic prediction\n\n\n\nOur implementation\nGLM\n\n\n\n\nBreen_Margaret_Isabella\n0.814\n0.811\n\n\nBreen_Patrick\n0.334\n0.338\n\n\nSpitzer_Augustus\n0.001\n0.000\n\n\nDonner_Isaac\n0.649\n0.650\n\n\nFoster_Sarah_Ann_Charlotte_Murphy\n0.724\n0.722"
  },
  {
    "objectID": "logistic.html#function-to-check-assumptions",
    "href": "logistic.html#function-to-check-assumptions",
    "title": "Logistic",
    "section": "Function to check assumptions",
    "text": "Function to check assumptions\n\ntest_logistic_assumptions &lt;- function(fn_formula, data) {\n  n &lt;- nrow(data)\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  Y &lt;- data[, y_name]\n\n  # outcome variables are binary\n  if (length(unique(Y)) == 2) {\n    assp_1 &lt;- paste(\"Binary outcomes assumption is met.\")\n  } else {\n    return(paste(\"Binary outcomes assumption is not satisfied. There are\", length(unique(Y)), \"outcomes.\"))\n  }\n\n  x_name &lt;- vars[2:length(vars)]\n  X &lt;- data[, x_name]\n  preds &lt;- logistic_function(fn_formula = fn_formula, data = data, predict = T) # predictions are in probability\n  logit_vals &lt;- log(preds / (1 - preds))\n  plot_data &lt;- data.frame(logit_vals, X) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -logit_vals)\n\n  # Linear relationship between the outcome variable and log odds of the predictor variables\n  assp_2 &lt;- ggplot(plot_data, aes(logit_vals, predictor_value)) +\n    geom_point(size = 0.5, alpha = 0.5) +\n    geom_smooth(method = \"loess\") +\n    theme_bw() +\n    facet_wrap(~predictors, scales = \"free_y\")\n\n  # Independence of errors\n  # plot residuals vs fits\n  model &lt;- glm(fn_formula, data = data, family = binomial)\n  assp_3 &lt;- plot(model, which = 1)\n\n  # No multicollinearity\n  assp_4 &lt;- cor(data[, -1])\n\n  predicted.values &lt;- ifelse(preds &gt;= 0.5, 1, 0)\n  check_perf &lt;- data.frame(Y, predicted.values) |&gt; mutate(correct = Y == predicted.values)\n  check_perf &lt;- paste0(mean(check_perf$correct) * 100, \"% classified correctly\")\n  return(list(assp_1, assp_2, print(assp_3), assp_4, check_perf))\n}\n\nn &lt;- 200\nx1 &lt;- rnorm(n, 2, 1)\nx2 &lt;- rnorm(n, 4, 1)\nprob &lt;- plogis(-1 + 1.2 * x1 - 0.5 * x2)\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nsim_data &lt;- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = sim_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n          x1        x2\nx1  1.000000 -0.018217\nx2 -0.018217  1.000000\n\n[[5]]\n[1] \"78.5% classified correctly\"\n\n\n\nFor binary logistic regression, that outcome variables are binary\nCheck how many unique outcome variables there are.\nIndependence of errors\nCheck residual plots.\nLinear relationship between the outcome variable and log odds of the predictor variables\nCheck scatterplots of log odds vs predictor variables to see that there is an approximately linear relationship.\nNo multicollinearity\nLook at the correlation matrix, generally any value over 0.9 is problematic."
  },
  {
    "objectID": "logistic.html#breaking-assumptions",
    "href": "logistic.html#breaking-assumptions",
    "title": "Logistic",
    "section": "Breaking assumptions",
    "text": "Breaking assumptions\n\n1. For binary logistic regression, that outcome variables are binary\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 2, 1)\nprob &lt;- plogis(-1 + 0.8 * x1)\ny &lt;- rpois(n, prob)\nbad_data &lt;- data.frame(y, x1)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1\", data = bad_data)\n\n[1] \"Binary outcomes assumption is not satisfied. There are 4 outcomes.\"\n\n\n\n\n2. Independence of errors\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 2, 1)\nx2 &lt;- rnorm(n, 0, 1)\nprob &lt;- plogis(-1.2 + 0.4 * x1 + 0.3 * x2 + rbeta(n, 2, 2))\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nbad_data &lt;- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = bad_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n           x1         x2\nx1 1.00000000 0.09361225\nx2 0.09361225 1.00000000\n\n[[5]]\n[1] \"62% classified correctly\"\n\n\nI used rbeta to introduce more error for the middle of the probabilities, which shows in the residual plot, where it looks like there is a peak in the fitted line around 0.\n\n\n3. Linear relationship between the outcome variable and log odds of the predictor variables\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 0, 1)\nx2 &lt;- rnorm(n, 2, 1)\nx3 &lt;- rnorm(n, -2, 1)\nprob &lt;- plogis(-1 + x1 * x2 + 1.3 * x2 - 0.5 * x3^2)\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nbad_data &lt;- data.frame(y, x1, x2, x3)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2 + x3\", data = bad_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n           x1          x2          x3\nx1  1.0000000 -0.16860022 -0.17308515\nx2 -0.1686002  1.00000000  0.02992617\nx3 -0.1730851  0.02992617  1.00000000\n\n[[5]]\n[1] \"82% classified correctly\"\n\n\nFor the probability used in the DGP, it is no longer a linear relationship of \\(X_i\\beta\\) but one that involves interactions and squared variables. The non-linear relationship is visible in the plots of the outcome variable vs log odds of each predictor variable.\n\n\n4. No multicollinearity\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 0, 1)\nx2 &lt;- rnorm(n, x1, 0.2)\nprob &lt;- plogis(-1 + x1 + 0.5 * x2)\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nbad_data &lt;- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = bad_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n          x1        x2\nx1 1.0000000 0.9847734\nx2 0.9847734 1.0000000\n\n[[5]]\n[1] \"80% classified correctly\"\n\n\nThe DGP involves \\(x2\\) being created from an rnorm around the mean of \\(x1\\), and a small SD so that it is even more correlated. The correlation matrix shows a problematically high correlation. The model still classifies fairly well, but what happens with multicollinearity is that it becomes difficult for the model to estimate the relationship between each predictor variable and the outcome variable independently because the predictor variables tend to change in unison. The p-values are also less trustworthy."
  },
  {
    "objectID": "logistic.html#next-steps",
    "href": "logistic.html#next-steps",
    "title": "Logistic",
    "section": "Next Steps",
    "text": "Next Steps\n\nInstead of just using maximum likelihood, we could try using iteratively reweighted least squares or Newton-Ralphson."
  },
  {
    "objectID": "logistic.html#conclusion",
    "href": "logistic.html#conclusion",
    "title": "Logistic",
    "section": "Conclusion",
    "text": "Conclusion\nBreaking certain assumptions do not make the logistic model classify worse. Independence of errors seems to be the worst case, but the rest do not change the correct classification rate much."
  },
  {
    "objectID": "note.html",
    "href": "note.html",
    "title": "A Note",
    "section": "",
    "text": "A Note\nIn determining how appropriate a particular regression model is for a problem, we think it might be valuable to move beyond a ‘assumption #1 met’ or ‘assumption #1 not met’ assessment. Instead, it might be more helpful for researchers to explore their data, and test assumptions on their own to determine ‘what level of assumption-violation’ might they be willing to accept given they are experts in their fields and have domain-specific contextual knowledge. This is not to say that assumptions can be violated without consequences.\nAlso, it might be difficult to determine the thresholds for having actually met or not met an assumption. Thus, a function which simply outputs a ‘yes’ or ‘no’ to whether assumptions for a particular regression implementation have been met did not seem appropriate. We therefore, test assumptions by intentionally breaking them and noting the extent of bias-ness that they result."
  },
  {
    "objectID": "negative-binomial.html",
    "href": "negative-binomial.html",
    "title": "Negative Binomial",
    "section": "",
    "text": "Negative Binomial Regression is used for predicting count data, similar to Poisson Regression, but the Negative Binomial is more flexible as it allows for the variance of the outcome to be greater than its mean (in Poisson Regression, they are assumed to be equal)."
  },
  {
    "objectID": "negative-binomial.html#introduction",
    "href": "negative-binomial.html#introduction",
    "title": "Negative Binomial",
    "section": "",
    "text": "Negative Binomial Regression is used for predicting count data, similar to Poisson Regression, but the Negative Binomial is more flexible as it allows for the variance of the outcome to be greater than its mean (in Poisson Regression, they are assumed to be equal)."
  },
  {
    "objectID": "negative-binomial.html#uses",
    "href": "negative-binomial.html#uses",
    "title": "Negative Binomial",
    "section": "Uses",
    "text": "Uses\nNegative Binomial Regression is used to model count data with excess zeros (as in the Zero-Inflated Negative Binomial Regression) and is used to model rare events which are less likely to have counts where mean = variance. Negative Binomial can be extended to handle correlated/clustered data as well."
  },
  {
    "objectID": "negative-binomial.html#assumptions",
    "href": "negative-binomial.html#assumptions",
    "title": "Negative Binomial",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe outcome represents count data\nThe variance of the outcome is greater than its mean\nThe relationship between the predictors and the log of the outcome’s mean is linear\nThe errors are independent of one another"
  },
  {
    "objectID": "negative-binomial.html#our-negative-binomial-regression-implementation",
    "href": "negative-binomial.html#our-negative-binomial-regression-implementation",
    "title": "Negative Binomial",
    "section": "Our Negative Binomial Regression Implementation",
    "text": "Our Negative Binomial Regression Implementation\nOur Negative Binomial Regression implementation: (Note that we use bootstrapping to estimate standard errors)\n\nnegative_binomial_regression &lt;- function(data, ..., y) {\n  n &lt;- nrow(data)\n  x_parameters &lt;- c(...)\n  # defining the predictor matrix\n  X &lt;-\n    matrix(c(rep(1, n), x_parameters),\n      nrow = n,\n      ncol = ncol(data)\n    )\n  # defining the outcome matrix\n  Y &lt;- matrix(y, nrow = n, ncol = 1)\n  # starting with theta = 1\n  theta &lt;- 1\n  # defining the log likelihood\n  negative_binomial.likelihood &lt;- function(beta, X, Y = y) {\n    eta &lt;- X %*% beta\n    mu &lt;- exp(eta)\n    loglikelihood &lt;-\n      sum(Y * log(mu) - (Y + 1 / theta) * log(1 + mu / theta))\n    return(loglikelihood)\n  }\n  # starting with an initial guess of the parameter values\n  initial_guess &lt;- rep(0, ncol(X))\n  # using 'optim' to maximize the log likelihood\n  result &lt;- optim(\n    initial_guess,\n    negative_binomial.likelihood,\n    X = X,\n    Y = Y,\n    control = list(fnscale = -1),\n    hessian = T,\n    method = NULL\n  )$par\n  # creating a vector 'estimate' for the beta coefficients\n  estimate &lt;- result\n  # bootstrapping to estimate the standard errors\n  num_bootstraps &lt;- 10\n  result_bootstrap &lt;-\n    matrix(0, nrow = num_bootstraps, ncol = ncol(X))\n  for (i in 1:num_bootstraps) {\n    sample_indices &lt;- sample(nrow(data), replace = TRUE)\n    bootstrap_data &lt;- data[sample_indices, ]\n    X_bootstrap &lt;-\n      matrix(\n        c(rep(1, nrow(bootstrap_data)), x_parameters),\n        nrow = nrow(bootstrap_data),\n        ncol = ncol(bootstrap_data)\n      )\n    Y_bootstrap &lt;-\n      matrix(bootstrap_data$y,\n        nrow = nrow(bootstrap_data),\n        ncol = 1\n      )\n    initial_guess_bootstrap &lt;-\n      matrix(0, nrow = ncol(bootstrap_data), ncol = 1)\n    result_bootstrap[i, ] &lt;- optim(\n      initial_guess_bootstrap,\n      negative_binomial.likelihood,\n      X = X_bootstrap,\n      Y = Y_bootstrap,\n      control = list(fnscale = -1),\n      hessian = T,\n      method = NULL\n    )$par\n  }\n  # finding the standard deviation of the bootstrapped betas to find the\n  # standard error of the coefficients\n  se &lt;- apply(result_bootstrap, 2, sd)\n  # calculating the z-statistic\n  z &lt;- estimate / se\n  # defining the degrees of freedom\n  df &lt;- nrow(X) - ncol(X)\n  # calculating the p-value\n  p &lt;- 2 * pnorm(z, lower.tail = FALSE)\n  # defining the row names of the output data frame\n  rownames &lt;- c()\n  for (i in 1:((ncol(X)) - 1)) {\n    rownames[i] &lt;- i\n  }\n  data_to_plot &lt;- data[, -which(colnames(data) == \"y\")]\n  data_to_plot$y_log &lt;- log(data$y)\n  test &lt;- list(\n    pairs(data_to_plot, main = \"Assessing Linearity of Predictors \\nwith log of Outcome\")\n  )\n  impl &lt;- data.frame(\n    Estimate = estimate,\n    Std.Error = se,\n    z.value = z,\n    p.value = p,\n    DegOfFreedom = c(df, rep(NA, ncol(X) - 1)),\n    row.names = c(\"(Intercept)\", paste0(rep(\"x\", ncol(\n      X\n    ) - 1), rownames))\n  )\n  # returning a data frame akin to the glm probit output\n  return(list(test, impl))\n}\n\nCreating a function to predict the outcomes based on our Negative Binomial Regression implementation.\n\npredict_neg_binom &lt;-\n  function(data, ..., y, implementation_neg_binom) {\n    n &lt;-\n      implementation_neg_binom$DegOfFreedom[1] + nrow(implementation_neg_binom)\n    input_covariate_values &lt;- c(...)\n    X &lt;-\n      matrix(\n        c(rep(1, n), input_covariate_values),\n        nrow = n,\n        ncol = nrow(implementation_neg_binom)\n      )\n    Y &lt;- matrix(y, nrow = n, ncol = 1)\n    estimate &lt;-\n      implementation_neg_binom[1:nrow(implementation_neg_binom), 1]\n    pred &lt;- exp(X %*% estimate)\n    return(pred)\n  }\n\nCreating a test data set which meets all Negative Binomial Regression assumptions to check if our function works.\n\nx1 &lt;- rnorm(100, mean = 0, sd = 0.5)\nx2 &lt;- rnorm(100, mean = 0, sd = 0.5)\ny &lt;- rnbinom(100, mu = exp(x1 + x2), size = 0.5)\ntest_neg_binom_regression_data &lt;- data.frame(x1, x2, y)\n# to ensure that the variance of the outcome variable is greater\n# than its mean\nvar(y) &gt; mean(y)\n\n[1] TRUE\n\nplot(test_neg_binom_regression_data$x1, log(test_neg_binom_regression_data$y),\n  main = \"The relationship between the log of the outcome and x1 is linear (it is not apparent in this plot but our data structure captures this relationship)\", cex.main = 0.4,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\nplot(test_neg_binom_regression_data$x2, log(test_neg_binom_regression_data$y),\n  xlab = \"x2\", ylab = \"y\",\n  main = \"The relationship between the log of the outcome and x2 is linear (it is not apparent in this plot but our data structure captures this relationship)\", cex.main = 0.4\n)"
  },
  {
    "objectID": "negative-binomial.html#testing-assumptions-for-negative-binomial-regression",
    "href": "negative-binomial.html#testing-assumptions-for-negative-binomial-regression",
    "title": "Negative Binomial",
    "section": "Testing Assumptions for Negative Binomial Regression",
    "text": "Testing Assumptions for Negative Binomial Regression\n\ntest_negbinom_reg &lt;- negative_binomial_regression(test_neg_binom_regression_data,\n  test_neg_binom_regression_data$x1,\n  test_neg_binom_regression_data$x2,\n  y = test_neg_binom_regression_data$y\n)[[1]]\n\n\n\n\n\n\n\n\nUsing our implementation of Negative Binomial to fit the model and get residual measure.\n\nour_implementation_neg_binom &lt;-\n  negative_binomial_regression(\n    test_neg_binom_regression_data,\n    test_neg_binom_regression_data$x1,\n    test_neg_binom_regression_data$x2,\n    y = test_neg_binom_regression_data$y\n  )[[2]]\n\n\n\n\n\n\n\nour_implementation_neg_binom\n\n              Estimate Std.Error  z.value    p.value DegOfFreedom\n(Intercept) 0.07019194 0.4237645 0.165639 0.86844102           97\nx1          1.08333669 0.7137122 1.517890 0.12904208           NA\nx2          1.08402921 0.4776059 2.269715 0.02322489           NA\n\n\nComparing our output to R’s output.\n\nr_implementation_neg_binom &lt;-\n  summary(glm.nb(y ~ x1 + x2, data = test_neg_binom_regression_data))\nr_implementation_neg_binom\n\n\nCall:\nglm.nb(formula = y ~ x1 + x2, data = test_neg_binom_regression_data, \n    init.theta = 0.2843070253, link = log)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.29425  -0.97170  -0.78659  -0.03923   1.85674  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  0.06525    0.21920   0.298   0.7660  \nx1           1.13741    0.48623   2.339   0.0193 *\nx2           1.08214    0.44280   2.444   0.0145 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.2843) family taken to be 1)\n\n    Null deviance: 86.734  on 99  degrees of freedom\nResidual deviance: 75.001  on 97  degrees of freedom\nAIC: 278.94\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.2843 \n          Std. Err.:  0.0718 \n\n 2 x log-likelihood:  -270.9420 \n\n\nWe note that the results are similar.\nWe followed all assumptions of Negative Binomial Regression in regressing y on x1 and x2 using the test_neg_binom_regression_data data set. We will compare the residual of this regression to that of all the others where assumptions will be broken.\nThe residual for where all assumptions are met:\n\nprediction_all_assumptions_met &lt;-\n  as.numeric(\n    predict_neg_binom(\n      test_neg_binom_regression_data,\n      test_neg_binom_regression_data$x1,\n      test_neg_binom_regression_data$x2,\n      y = test_neg_binom_regression_data$y,\n      implementation_neg_binom = our_implementation_neg_binom\n    )\n  )\nresidual_all_assumptions_met &lt;- sqrt(mean((\n  test_neg_binom_regression_data$y - prediction_all_assumptions_met\n)^2))\nresidual_all_assumptions_met # small residual\n\n[1] 3.442564\n\n# residual plot\nplot(\n  test_neg_binom_regression_data$y - prediction_all_assumptions_met,\n  ylim = c(-30, 30),\n  ylab = \"Residuals\",\n  main = \"Residual Plot: All assumptions met\",\n  pch = 16\n)\nabline(\n  h = 0,\n  col = \"red\",\n  lty = 2,\n  lwd = 3\n)"
  },
  {
    "objectID": "negative-binomial.html#breaking-assumptions",
    "href": "negative-binomial.html#breaking-assumptions",
    "title": "Negative Binomial",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nBreaking the assumption that the relationship between the predictors and the log of the outcome’s mean is linear\nCreating a data set where, if we apply Negative Binomial regression, this assumption will be broken.\n\nx1 &lt;- rnorm(100, mean = 0, sd = 0.5)\nx2 &lt;- rnorm(100, mean = 0, sd = 0.5)\ny &lt;- rnbinom(100, mu = exp(x1 + x2)^2, size = 0.5)\ntest_neg_binom_regression_data_not_linear &lt;- data.frame(x1, x2, y)\n# to ensure that the variance of the outcome variable is greater\n# than its mean\nvar(y) &gt; mean(y)\n\n[1] TRUE\n\nplot(test_neg_binom_regression_data_not_linear$x1, log(test_neg_binom_regression_data_not_linear$y),\n  main = \"The relationship between the log of the outcome and x1 is not linear\", cex.main = 0.8,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\nplot(test_neg_binom_regression_data_not_linear$x2, log(test_neg_binom_regression_data_not_linear$y),\n  xlab = \"x2\", ylab = \"y\", cex.main = 0.8,\n  main = \"The relationship between the log of the outcome and x2 is not linear\"\n)\n\n\n\n\n\n\n\n\nUsing our implementation of Negative Binomial to fit the model and get a residual measure.\n\nour_implementation_neg_binom_not_linear &lt;-\n  negative_binomial_regression(\n    test_neg_binom_regression_data_not_linear,\n    test_neg_binom_regression_data_not_linear$x1,\n    test_neg_binom_regression_data_not_linear$x2,\n    y = test_neg_binom_regression_data_not_linear$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_not_linear &lt;-\n  as.numeric(\n    predict_neg_binom(\n      test_neg_binom_regression_data_not_linear,\n      test_neg_binom_regression_data_not_linear$x1,\n      test_neg_binom_regression_data_not_linear$x2,\n      y = test_neg_binom_regression_data_not_linear$y,\n      implementation_neg_binom = our_implementation_neg_binom_not_linear\n    )\n  )\nresidual_not_linear &lt;- sqrt(mean((\n  test_neg_binom_regression_data_not_linear$y - prediction_not_linear\n)^2))\nresidual_not_linear # large residual\n\n[1] 7.155735\n\n# residual plot\nplot(\n  test_neg_binom_regression_data_not_linear$y - prediction_not_linear,\n  ylim = c(-30, 30),\n  ylab = \"Residuals\",\n  main = \"Residual Plot: Linearity assumption violated\",\n  pch = 16\n)\nabline(\n  h = 0,\n  col = \"red\",\n  lty = 2,\n  lwd = 3\n)\n\n\n\n\n\n\n\n\n\n\nBreaking the assumption that the mean of the outcome is smaller than its variance\nCreating a data set where, if we apply Negative Binomial regression, this assumption will be broken.\n\nx1 &lt;- rnorm(100, mean = 0, sd = 0.5)\nx2 &lt;- rnorm(100, mean = 0, sd = 0.5)\ny &lt;- rnbinom(100, mu = exp(x2 - 2 * x1), size = 100) + 10\ntest_neg_binom_regression_data_mean_greater &lt;- data.frame(x1, x2, y)\n# to ensure that the variance of the outcome variable is smaller\n# than its mean\nvar(y) &gt; mean(y)\n\n[1] FALSE\n\n\nUsing our implementation of Negative Binomial to fit the model and get a residual measure.\n\nour_implementation_neg_binom_mean_greater &lt;-\n  negative_binomial_regression(\n    test_neg_binom_regression_data_mean_greater,\n    test_neg_binom_regression_data_mean_greater$x1,\n    test_neg_binom_regression_data_mean_greater$x2,\n    y = test_neg_binom_regression_data_mean_greater$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_mean_greater &lt;-\n  as.numeric(\n    predict_neg_binom(\n      test_neg_binom_regression_data_mean_greater,\n      test_neg_binom_regression_data_mean_greater$x1,\n      test_neg_binom_regression_data_mean_greater$x2,\n      y = test_neg_binom_regression_data_mean_greater$y,\n      implementation_neg_binom = our_implementation_neg_binom_mean_greater\n    )\n  )\nresidual_mean_greater &lt;- sqrt(mean((\n  test_neg_binom_regression_data_mean_greater$y - prediction_mean_greater\n)^2))\nresidual_mean_greater\n\n[1] 1.601529\n\n# residual plot\nplot(\n  test_neg_binom_regression_data_mean_greater$y - prediction_mean_greater,\n  ylim = c(-30, 30),\n  ylab = \"Residuals\",\n  cex.main = 0.9,\n  main = \"Residual Plot: Variance of outcome greater than mean assumption violated\",\n  pch = 16\n)\nabline(\n  h = 0,\n  col = \"red\",\n  lty = 2,\n  lwd = 3\n)"
  },
  {
    "objectID": "negative-binomial.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "href": "negative-binomial.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "title": "Negative Binomial",
    "section": "Comparing residuals when all assumptions were met versus not",
    "text": "Comparing residuals when all assumptions were met versus not\n\nresidual_comparison &lt;-\n  t(\n    data.frame(\n      residual_all_assumptions_met,\n      residual_not_linear,\n      residual_mean_greater\n    )\n  )\nrow.names(residual_comparison) &lt;- c(\n  \"All assumptions met\",\n  \"Linearity assumption violated\",\n  \"Variance &gt; Mean assumption violated\"\n)\ncolnames(residual_comparison) &lt;- \"Residuals\"\nresidual_comparison\n\n                                    Residuals\nAll assumptions met                  3.442564\nLinearity assumption violated        7.155735\nVariance &gt; Mean assumption violated  1.601529"
  },
  {
    "objectID": "negative-binomial.html#conclusion",
    "href": "negative-binomial.html#conclusion",
    "title": "Negative Binomial",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation of Negative Binomial Regression where all assumptions are met performs well; however, even the model where an assumption is broken; i.e. where the mean of the outcome is greater than its variance, performs well too - however, it should be noted that even though its predictions might be accurate, its standard errors and p-values might be biased.\n\nset.seed(123)\nlibrary(alr4)\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(pscl)\nlibrary(glmbb) # for crabs data\nlibrary(kableExtra)\nlibrary(lmtest)"
  },
  {
    "objectID": "probit.html",
    "href": "probit.html",
    "title": "Probit",
    "section": "",
    "text": "The Probit model classifies observations into one of two categories (for simple Probit Regression; multinomial Probit Regression can classify observations into more than two categories) by estimating the probability that an observation with particular characteristics is more likely to fall in one category or another."
  },
  {
    "objectID": "probit.html#introduction",
    "href": "probit.html#introduction",
    "title": "Probit",
    "section": "",
    "text": "The Probit model classifies observations into one of two categories (for simple Probit Regression; multinomial Probit Regression can classify observations into more than two categories) by estimating the probability that an observation with particular characteristics is more likely to fall in one category or another."
  },
  {
    "objectID": "probit.html#uses",
    "href": "probit.html#uses",
    "title": "Probit",
    "section": "Uses",
    "text": "Uses\nProbit Regression is primarily used when the outcome is binary - thus, it is mainly used for classification problems. When covariates are continuous, there are infinite possible values for the outcome if using Linear Regression; Logistic and Probit Regressions are therefore better than Linear if we need to bound the outcome to 0 and 1.\nLogistic Regression and Probit Regressions give almost identical results - they just have different link functions. The decision to chose one over the other is discipline-dependent, and it is said that Logistic Regression is better when one has extreme independent variables (where one particular small or large value will overwhelmingly determine if your outcome is 0 or 1 - overriding the effect of most other variables). However, there is no ‘right’ answer to this debate."
  },
  {
    "objectID": "probit.html#assumptions",
    "href": "probit.html#assumptions",
    "title": "Probit",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe outcome is binary\nThe z-score of the outcome and the predictor variables have a linear relationship\nThe errors are normally distributed and are independent of one another"
  },
  {
    "objectID": "probit.html#our-probit-regression-implementation",
    "href": "probit.html#our-probit-regression-implementation",
    "title": "Probit",
    "section": "Our Probit Regression Implementation",
    "text": "Our Probit Regression Implementation\nOur Probit Regression implementation: (Note that we use bootstrapping to estimate standard errors)\n\nprobit_regression &lt;- function(data, ..., y) {\n  n &lt;- nrow(data)\n  x_parameters &lt;- c(...)\n  # defining the predictor matrix\n  X &lt;-\n    matrix(c(rep(1, n), x_parameters),\n      nrow = n,\n      ncol = ncol(data)\n    )\n  # defining the outcome matrix\n  Y &lt;- matrix(y, nrow = n, ncol = 1)\n  # defining the log likelihood\n  probit.loglikelihood &lt;- function(beta, X, Y) {\n    eta &lt;- X %*% beta\n    p &lt;- pnorm(eta)\n    loglikelihood &lt;- -sum((1 - Y) * log(1 - p) + Y * log(p))\n    return(loglikelihood)\n  }\n  # starting with an initial guess of the parameter values\n  initial_guess &lt;- matrix(0, nrow = ncol(data), ncol = 1)\n  # using 'optim' to maximize the log likelihood\n  result &lt;- optim(\n    initial_guess,\n    fn = probit.loglikelihood,\n    X = X,\n    Y = Y,\n    method = NULL\n  )$par\n  # creating a vector 'estimate' for the beta coefficients\n  estimate &lt;- result\n  # bootstrapping to estimate the standard errors\n  num_bootstraps &lt;- 10\n  result_bootstrap &lt;-\n    matrix(0, nrow = num_bootstraps, ncol = ncol(X))\n  for (i in 1:num_bootstraps) {\n    sample_indices &lt;- sample(nrow(data), replace = TRUE)\n    bootstrap_data &lt;- data[sample_indices, ]\n    X_bootstrap &lt;-\n      matrix(\n        c(rep(1, nrow(bootstrap_data)), x_parameters),\n        nrow = nrow(bootstrap_data),\n        ncol = ncol(bootstrap_data)\n      )\n    Y_bootstrap &lt;-\n      matrix(bootstrap_data$y,\n        nrow = nrow(bootstrap_data),\n        ncol = 1\n      )\n    initial_guess_bootstrap &lt;-\n      matrix(0, nrow = ncol(bootstrap_data), ncol = 1)\n    result_bootstrap[i, ] &lt;- optim(\n      initial_guess_bootstrap,\n      probit.loglikelihood,\n      X = X_bootstrap,\n      Y = Y_bootstrap,\n      method = NULL\n    )$par\n  }\n  # finding the standard deviation of the bootstrapped betas to find the\n  # standard error of the coefficients\n  se &lt;- apply(result_bootstrap, 2, sd)\n  # calculating the z-statistic\n  z &lt;- estimate / se\n  # defining the degrees of freedom\n  df &lt;- nrow(X) - ncol(X)\n  # calculating the p-value\n  p &lt;- 2 * pnorm(z, lower.tail = FALSE)\n  # defining the row names of the output data frame\n  rownames &lt;- c()\n  for (i in 1:((ncol(X)) - 1)) {\n    rownames[i] &lt;- i\n  }\n  data_to_plot &lt;- data[, -which(colnames(data) == \"y\")]\n  data_to_plot$y_zscore &lt;- qnorm(pnorm(data$y))\n  test &lt;- list(\n    pairs(data_to_plot, main = \"Assessing Linearity of Predictors\\n with z score of Outcome\")\n  )\n  impl &lt;- data.frame(\n    Estimate = estimate,\n    Std.Error = se,\n    z.value = z,\n    p.value = p,\n    DegOfFreedom = c(df, rep(NA, ncol(X) - 1)),\n    row.names = c(\"(Intercept)\", paste0(rep(\"x\", ncol(\n      X\n    ) - 1), rownames))\n  )\n  # returning a data frame akin to the glm probit output\n  return(list(test, impl))\n}\n\nCreating a function to predict the outcomes based on our Probit Regression implementation.\n\npredict_probit &lt;-\n  function(data, ..., y, implementation_probit) {\n    n &lt;-\n      implementation_probit$DegOfFreedom[1] + nrow(implementation_probit)\n    input_covariate_values &lt;- c(...)\n    X &lt;-\n      matrix(\n        c(rep(1, n), input_covariate_values),\n        nrow = n,\n        ncol = nrow(implementation_probit)\n      )\n    Y &lt;- matrix(y, nrow = n, ncol = 1)\n    estimate &lt;-\n      implementation_probit[1:nrow(implementation_probit), 1]\n    pred &lt;- ifelse(X %*% estimate &lt; 0, 0, 1)\n    return(pred)\n  }\n\nCreating a test data set which meets all Probit Regression assumptions to check if our function works.\n\ntest_probit_regression_data &lt;- data.frame(\n  x1 = rnorm(1000, 0, 1),\n  x2 = rnorm(1000, 0, 1)\n)\nerror &lt;- rnorm(1000, mean = 0, sd = 0.5)\ntest_probit_regression_data$y &lt;- test_probit_regression_data$x1 +\n  0.5 * test_probit_regression_data$x2 +\n  error\ntest_probit_regression_data$y &lt;-\n  qnorm(pnorm(test_probit_regression_data$y))\n\nplot(test_probit_regression_data$x1, test_probit_regression_data$y,\n  main = \"The z score of y and x1 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\nplot(test_probit_regression_data$x1, test_probit_regression_data$y,\n  main = \"The z score of y and x2 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x2\", ylab = \"y\"\n)\n\n\n\n\n\n\n\ntest_probit_regression_data$y &lt;-\n  ifelse(test_probit_regression_data$y &lt; 0, 0, 1)\n\nplot(density(error), main = \"Errors are normally distributed\")"
  },
  {
    "objectID": "probit.html#testing-assumptions-for-probit-regression",
    "href": "probit.html#testing-assumptions-for-probit-regression",
    "title": "Probit",
    "section": "Testing Assumptions for Probit Regression",
    "text": "Testing Assumptions for Probit Regression\n\ntest_probit_reg &lt;- probit_regression(test_probit_regression_data,\n  test_probit_regression_data$x1,\n  test_probit_regression_data$x2,\n  y = test_probit_regression_data$y\n)[[1]]\n\n\n\n\n\n\n\n\nApplying the function we created on this data set.\n\nour_implementation_probit &lt;-\n  probit_regression(\n    test_probit_regression_data,\n    test_probit_regression_data$x1,\n    test_probit_regression_data$x2,\n    y = test_probit_regression_data$y\n  )[[2]]\n\n\n\n\n\n\n\nour_implementation_probit\n\n               Estimate  Std.Error   z.value       p.value DegOfFreedom\n(Intercept) -0.09036983 0.04232593 -2.135094  1.967247e+00          997\nx1           1.99232295 0.03188065 62.493167  0.000000e+00           NA\nx2           1.03345197 0.04472044 23.109165 3.744892e-118           NA\n\n\nComparing our output to R’s output.\n\nr_implementation_probit &lt;-\n  summary(glm(y ~ x1 + x2,\n    data = test_probit_regression_data,\n    family = binomial(link = \"probit\")\n  ))\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nr_implementation_probit\n\n\nCall:\nglm(formula = y ~ x1 + x2, family = binomial(link = \"probit\"), \n    data = test_probit_regression_data)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.82426  -0.34561  -0.00006   0.40909   2.68617  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.09085    0.05918  -1.535    0.125    \nx1           1.99294    0.12348  16.139   &lt;2e-16 ***\nx2           1.03360    0.08103  12.756   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1386.23  on 999  degrees of freedom\nResidual deviance:  586.45  on 997  degrees of freedom\nAIC: 592.45\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe note that the results are similar.\nWe followed all assumptions of Probit Regression in regressing y on x1 and x2 using the test_probit_regression_data data set. We will compare the residual of this regression to that of all the others where assumptions will be broken.\nThe accuracy for where all assumptions are met:\n\nprediction_all_assumptions_met &lt;-\n  as.numeric(\n    predict_probit(\n      test_probit_regression_data,\n      test_probit_regression_data$x1,\n      test_probit_regression_data$x2,\n      y = test_probit_regression_data$y,\n      implementation_probit = our_implementation_probit\n    )\n  )\naccuracy_all_assumptions_met &lt;-\n  sum(prediction_all_assumptions_met == test_probit_regression_data$y) / 1000\naccuracy_all_assumptions_met # high accuracy here\n\n[1] 0.873"
  },
  {
    "objectID": "probit.html#breaking-assumptions",
    "href": "probit.html#breaking-assumptions",
    "title": "Probit",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nBreaking the assumption that the relationship between the predictors and the z score of y is linear\nCreating a data set where, if we apply Probit Regression, this assumption will be broken.\n\ntest_probit_regression_data_not_linear &lt;-\n  data.frame(\n    x1 = rnorm(1000, 0, 1),\n    x2 = rnorm(1000, 0, 1)\n  )\neror &lt;- rnorm(1000, mean = 0, sd = 0.5)\ntest_probit_regression_data_not_linear$y &lt;-\n  test_probit_regression_data_not_linear$x1^2 + error\ntest_probit_regression_data_not_linear$y &lt;-\n  qnorm(pnorm(test_probit_regression_data_not_linear$y))\n\nplot(test_probit_regression_data_not_linear$x1, test_probit_regression_data_not_linear$y,\n  main = \"The z score of y and x1 \\ndo not have a linear relationship\",\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\ntest_probit_regression_data_not_linear$y &lt;-\n  ifelse(test_probit_regression_data_not_linear$y &lt; 0, 0, 1)\n\nUsing our implementation of glm Probit to fit the model and get an accuracy measure.\n\nour_implementation_probit_not_linear &lt;-\n  probit_regression(\n    test_probit_regression_data_not_linear,\n    test_probit_regression_data_not_linear$x1,\n    test_probit_regression_data_not_linear$x2,\n    y = test_probit_regression_data_not_linear$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_not_linear &lt;-\n  as.numeric(\n    predict_probit(\n      test_probit_regression_data_not_linear,\n      test_probit_regression_data_not_linear$x1,\n      test_probit_regression_data_not_linear$x2,\n      y = test_probit_regression_data_not_linear$y,\n      implementation_probit = our_implementation_probit_not_linear\n    )\n  )\naccuracy_not_linear &lt;-\n  sum(prediction_not_linear == test_probit_regression_data_not_linear$y) / 1000\naccuracy_not_linear # lower accuracy here\n\n[1] 0.777\n\n\nWe note that Probit Regression is not performing as well in this case.\n\n\nBreaking the assumption that the errors are normally distributed\nCreating a data set where, if we apply Probit Regression, this assumption will be broken.\n\ntest_probit_regression_data_not_normally_dist &lt;-\n  data.frame(\n    x1 = rnorm(1000, 0, 1),\n    x2 = rnorm(1000, 0, 1)\n  )\nerror &lt;- runif(1000, min = -1, max = 1)\ntest_probit_regression_data_not_normally_dist$y &lt;-\n  test_probit_regression_data_not_normally_dist$x1 + error\ntest_probit_regression_data_not_normally_dist$y &lt;-\n  qnorm(pnorm(test_probit_regression_data_not_normally_dist$y))\n\nplot(density(error), main = \"Errors are not normally distributed\")\n\n\n\n\n\n\n\ntest_probit_regression_data_not_normally_dist$y &lt;-\n  ifelse(test_probit_regression_data_not_normally_dist$y &lt; 0, 0, 1)\n\nUsing our implementation of glm Probit to fit the model and get an accuracy measure.\n\nour_implementation_probit_not_normally_dist &lt;-\n  probit_regression(\n    test_probit_regression_data_not_normally_dist,\n    test_probit_regression_data_not_normally_dist$x1,\n    test_probit_regression_data_not_normally_dist$x2,\n    y = test_probit_regression_data_not_normally_dist$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_not_normally_dist &lt;-\n  as.numeric(\n    predict_probit(\n      test_probit_regression_data_not_normally_dist,\n      test_probit_regression_data_not_normally_dist$x1,\n      test_probit_regression_data_not_normally_dist$x2,\n      y = test_probit_regression_data_not_normally_dist$y,\n      implementation_probit = our_implementation_probit_not_normally_dist\n    )\n  )\naccuracy_not_normally_dist &lt;-\n  sum(prediction_not_normally_dist == test_probit_regression_data_not_normally_dist$y) / 1000\naccuracy_not_normally_dist # lower accuracy here\n\n[1] 0.814\n\n\nWe note that Probit Regression is not performing as well in this case."
  },
  {
    "objectID": "probit.html#comparing-accuracies-when-all-assumptions-were-met-versus-not",
    "href": "probit.html#comparing-accuracies-when-all-assumptions-were-met-versus-not",
    "title": "Probit",
    "section": "Comparing accuracies when all assumptions were met versus not",
    "text": "Comparing accuracies when all assumptions were met versus not\n\naccuracy_comparison &lt;-\n  t(\n    data.frame(\n      accuracy_all_assumptions_met,\n      accuracy_not_linear,\n      accuracy_not_normally_dist\n    )\n  )\nrow.names(accuracy_comparison) &lt;- c(\n  \"All assumptions met\",\n  \"Linearity assumption violated\",\n  \"Normality assumption violated\"\n)\ncolnames(accuracy_comparison) &lt;- \"Accuracy\"\naccuracy_comparison\n\n                              Accuracy\nAll assumptions met              0.873\nLinearity assumption violated    0.777\nNormality assumption violated    0.814"
  },
  {
    "objectID": "probit.html#conclusion",
    "href": "probit.html#conclusion",
    "title": "Probit",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation of Probit Regression where all assumptions are met performs the best; i.e. it gives us predictions which are more accurate to the true outcome values."
  },
  {
    "objectID": "regressions/zipoisson.html",
    "href": "regressions/zipoisson.html",
    "title": "Zero-Inflated Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data, but if may not be the best model when there are excess zeroes in that data, which is when we may use Zero-inflated poisson regression instead. ZIP models have one parameter representing the probability of a structured zero, and another representing the Poisson mean. The ZIP distribution has the parameters \\(\\pi\\) and \\(\\lambda\\), denoted by \\(ZIP(\\pi, \\lambda)\\), with this probability mass function.\n\\[\\begin{equation}\n  P(X=k) =\n    \\begin{cases}\n      \\pi + (1-\\pi)(exp(-\\lambda)) & \\text{if $k = 0$}\\\\\n      (1-\\pi)exp(-\\lambda)\\frac{\\lambda^k}{k!} & \\text{if $k = 1, 2, 3, ...$}\\\\\n    \\end{cases}       \n\\end{equation}\\]\nThe figure below shows a zero-inflated Poisson model, where the zeros are either sampling zeros or structural zeros."
  },
  {
    "objectID": "regressions/zipoisson.html#introduction",
    "href": "regressions/zipoisson.html#introduction",
    "title": "Zero-Inflated Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data, but if may not be the best model when there are excess zeroes in that data, which is when we may use Zero-inflated poisson regression instead. ZIP models have one parameter representing the probability of a structured zero, and another representing the Poisson mean. The ZIP distribution has the parameters \\(\\pi\\) and \\(\\lambda\\), denoted by \\(ZIP(\\pi, \\lambda)\\), with this probability mass function.\n\\[\\begin{equation}\n  P(X=k) =\n    \\begin{cases}\n      \\pi + (1-\\pi)(exp(-\\lambda)) & \\text{if $k = 0$}\\\\\n      (1-\\pi)exp(-\\lambda)\\frac{\\lambda^k}{k!} & \\text{if $k = 1, 2, 3, ...$}\\\\\n    \\end{cases}       \n\\end{equation}\\]\nThe figure below shows a zero-inflated Poisson model, where the zeros are either sampling zeros or structural zeros."
  },
  {
    "objectID": "regressions/zipoisson.html#uses",
    "href": "regressions/zipoisson.html#uses",
    "title": "Zero-Inflated Poisson",
    "section": "Uses",
    "text": "Uses\nAn example of when ZIP-distributed count happens is when ecologists counting plants or animals get a zero when the species is absent at many sites, but get a Poisson distributed count when they are present. Another example is for estimating the the dental health of individuals, by counting how many dental cavities there are. Most people have 0 dental cavities as children, so this is a good use case for ZIP."
  },
  {
    "objectID": "regressions/zipoisson.html#assumptions",
    "href": "regressions/zipoisson.html#assumptions",
    "title": "Zero-Inflated Poisson",
    "section": "Assumptions",
    "text": "Assumptions\n\nIt follows the same assumptions for the Poisson regression for the counts generated by the Poisson process, and assumptions that apply for the logistic model that models the probability of being a zero."
  },
  {
    "objectID": "regressions/zipoisson.html#our-zero-inflated-poisson-regression-implementation",
    "href": "regressions/zipoisson.html#our-zero-inflated-poisson-regression-implementation",
    "title": "Zero-Inflated Poisson",
    "section": "Our Zero-inflated Poisson Regression Implementation",
    "text": "Our Zero-inflated Poisson Regression Implementation\n\nzippoisson_function &lt;- function(fn_formula, data) {\n  number_omitted &lt;- nrow(data) - nrow(na.omit(data))\n  data &lt;- na.omit(data)\n\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  covL &lt;- data[, vars[2]]\n  covp &lt;- data[, vars[3]]\n  n &lt;- nrow(data)\n  Y &lt;- matrix(data[, y_name], nrow = n, ncol = 1)\n\n  optim_zip &lt;- function(beta) {\n    lambda &lt;- exp(beta[1] + beta[2] * covL)\n    p &lt;- plogis(beta[3] + beta[4] * covp)\n    lik &lt;- p * (Y == 0) + (1 - p) * dpois(Y, lambda)\n    return(-sum(log(lik)))\n  }\n  result &lt;- optim(par = rep(0, 4), fn = optim_zip, hessian = T)\n  OI &lt;- solve(result$hessian)\n  se &lt;- sqrt(diag(OI))\n  z_value &lt;- result$par / se\n  p_value &lt;- 2 * pnorm(-1 * abs(z_value))\n\n  coef &lt;- rbind(result$par, se, z_value, p_value)\n\n  colnames(coef) &lt;- c(\"(Intercept)\", vars[2], \"(Intercept)\", vars[3])\n  rownames(coef) &lt;- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n  return(t(coef))\n}\n\nComparing performance\n\nn &lt;- 1000\ncovL &lt;- seq(0, 1, length.out = n)\ncovp &lt;- seq(0, 1, length.out = n)\ntrueMeans &lt;- exp(1.5 - 0.5 * covL)\nprobability &lt;- plogis(-0.5 + 2.5 * covp)\nU &lt;- runif(n, 0, 1)\ny &lt;- rpois(n, trueMeans)\ny[U &lt; probability] &lt;- 0\nzip_data &lt;- data.frame(y, covL, covp)\nhist(zip_data$y, main = \"Histogram of Zero-inflated Poisson data\", xlab = \"Count\")\n\n\n\n\n\n\n\n# comparing performance of our implementation with zeroinfl\nzippoisson_function(fn_formula = \"y ~ covL | covp\", data = zip_data)\n\n              Estimate Std. Error   z value       p value\n(Intercept)  1.5110398 0.04973986 30.378851 1.045285e-202\ncovL        -0.6505926 0.12418413 -5.238935  1.615060e-07\n(Intercept) -0.4266365 0.13620157 -3.132390  1.733893e-03\ncovp         2.4480016 0.26972049  9.076069  1.125674e-19\n\nsummary(pscl::zeroinfl(y ~ covL | covp))$coef\n\n$count\n              Estimate Std. Error   z value      Pr(&gt;|z|)\n(Intercept)  1.5111633 0.04973736 30.382862 9.252314e-203\ncovL        -0.6508453 0.12418346 -5.240998  1.597104e-07\n\n$zero\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.4263151  0.1362002 -3.130062 1.747691e-03\ncovp         2.4477580  0.2697245  9.075029 1.136467e-19"
  },
  {
    "objectID": "regressions/zipoisson.html#checking-assumptions",
    "href": "regressions/zipoisson.html#checking-assumptions",
    "title": "Zero-Inflated Poisson",
    "section": "Checking Assumptions",
    "text": "Checking Assumptions\n\nSuitability for ZIP or Poisson\nUsing the crabs data again, we will check the suitability for ZIP or Poisson with a likelihood ratio test.\n\nzip_model &lt;- pscl::zeroinfl(satell ~ width | width, data = crabs)\npois_model &lt;- glm(satell ~ width, family = poisson, data = crabs)\nlmtest::lrtest(zip_model, pois_model)\n\nWarning in modelUpdate(objects[[i - 1]], objects[[i]]): original model was of\nclass \"zeroinfl\", updated model is of class \"glm\"\n\n\nLikelihood ratio test\n\nModel 1: satell ~ width | width\nModel 2: satell ~ width\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 -364.82                         \n2   2 -461.59 -2 193.53  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf we set the significance level at 0.05, the likelihood ratio test shows that we should reject the null hypothesis, so the ZIP model offers an improvement in fit over the Poisson model, since the ZIP model has a log likelihood closer to zero.\n\npois_model &lt;- glm(y ~ covL + covp, data = zip_data)\nzip_model &lt;- pscl::zeroinfl(y ~ covL | covp, data = zip_data)\nlmtest::lrtest(zip_model, pois_model)\n\nWarning in modelUpdate(objects[[i - 1]], objects[[i]]): original model was of\nclass \"zeroinfl\", updated model is of class \"glm\"\n\n\nLikelihood ratio test\n\nModel 1: y ~ covL | covp\nModel 2: y ~ covL + covp\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 -1189.3                         \n2   3 -2060.6 -1 1742.6  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis likelihood ratio test of our own constructed dataset following a ZIP distribution also has a p-value of smaller than 0.05, and that the ZIP model has a log likelihood closer to zero, indicating better suitability for a ZIP model."
  },
  {
    "objectID": "regressions/zipoisson.html#conclusion",
    "href": "regressions/zipoisson.html#conclusion",
    "title": "Zero-Inflated Poisson",
    "section": "Conclusion",
    "text": "Conclusion\nZIP models provide a flexible framework by combining a Poisson distribution for positive counts with a logistic regression component to model the excess zeros. It is most appropriate to plot the data and see whether a dataset containing a count response variable is suited for Poisson or ZIP, and then conducting a likelihood ratio test to compare them."
  },
  {
    "objectID": "regressions/linear.html",
    "href": "regressions/linear.html",
    "title": "Linear",
    "section": "",
    "text": "Linear Regression is one of the simplest regressions out there. In predicting an outcome from various covariate(s), it creates the ‘best-fitting’ line to the data that we observe to create a model - in that it predicts values on the line when given specific values of the covariates."
  },
  {
    "objectID": "regressions/linear.html#introduction",
    "href": "regressions/linear.html#introduction",
    "title": "Linear",
    "section": "",
    "text": "Linear Regression is one of the simplest regressions out there. In predicting an outcome from various covariate(s), it creates the ‘best-fitting’ line to the data that we observe to create a model - in that it predicts values on the line when given specific values of the covariates."
  },
  {
    "objectID": "regressions/linear.html#uses",
    "href": "regressions/linear.html#uses",
    "title": "Linear",
    "section": "Uses",
    "text": "Uses\nLinear Regression is used across various fields. It is a model which has high bias and low variance. This means that even though it may not fit the data observed in the most optimal way (in that it may not be able to capture complexities in the data), it is not that sensitive to changes in the training data, which can make it more stable when dealing with small fluctuations or noise in the data set. Linear Regression can be used for predicting continuous, categorical, and even binary outcomes (as is often done in Causal Inference)."
  },
  {
    "objectID": "regressions/linear.html#assumptions",
    "href": "regressions/linear.html#assumptions",
    "title": "Linear",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe predictors and the outcome are linearly related to one another\nThe errors are normally distributed and are independent of one another\nThe errors are homoscedastic"
  },
  {
    "objectID": "regressions/linear.html#our-linear-regression-implementation",
    "href": "regressions/linear.html#our-linear-regression-implementation",
    "title": "Linear",
    "section": "Our Linear Regression Implementation",
    "text": "Our Linear Regression Implementation\nOur Linear Regression implementation: (Note that we use bootstrapping to estimate standard errors)\n\nlinear_regression &lt;- function(data, ..., y) {\n  x_parameters &lt;- c(...)\n  n &lt;- nrow(data)\n  # defining the predictor matrix\n  X &lt;-\n    matrix(c(rep(1, n), x_parameters),\n      nrow = n,\n      ncol = ncol(data)\n    )\n  # defining the outcome matrix\n  Y &lt;- matrix(y, nrow = n, ncol = 1)\n  # solving for the beta coefficients\n  beta &lt;- solve(t(X) %*% X) %*% t(X) %*% Y\n  # creating a vector 'estimate' for the beta coefficients\n  estimate &lt;- c()\n  for (i in 1:ncol(X)) {\n    estimate[i] &lt;- beta[i]\n  }\n  # bootstrapping to estimate the standard errors\n  num_bootstraps &lt;- 10000\n  bootstrap_betas &lt;-\n    matrix(0, nrow = num_bootstraps, ncol = ncol(data))\n  for (i in 1:num_bootstraps) {\n    sample_indices &lt;- sample(nrow(data), replace = TRUE)\n    bootstrap_data &lt;- data[sample_indices, ]\n    bootstrap_X &lt;-\n      as.matrix(cbind(1, bootstrap_data[, 1:(ncol(bootstrap_data) - 1)]))\n    bootstrap_Y &lt;- as.matrix(bootstrap_data$y, ncol = 1)\n    bootstrap_beta &lt;-\n      solve(t(bootstrap_X) %*% bootstrap_X) %*% t(bootstrap_X) %*% bootstrap_Y\n    bootstrap_betas[i, ] &lt;- bootstrap_beta\n  }\n  # finding the standard deviation of the bootstrapped betas to find the\n  # standard error of the coefficients\n  se &lt;- c()\n  for (i in 1:ncol(X)) {\n    se[i] &lt;- apply(bootstrap_betas, 2, sd)[i]\n  }\n  # calculating the t-statistic\n  t &lt;- estimate / se\n  # defining the degrees of freedom\n  df &lt;- nrow(X) - ncol(X)\n  # calculating the p-value\n  p &lt;- 2 * pt(t, df, lower = F)\n  # calculating the residuals\n  resid &lt;- Y - X %*% beta\n  residual &lt;- sqrt(mean((resid)^2))\n  # defining the row names of the output data frame\n  rownames &lt;- c()\n  for (i in 1:((ncol(X)) - 1)) {\n    rownames[i] &lt;- i\n  }\n  test &lt;- list(\n    plot(resid, main = \"Residual Plot to test homoscedasticity of errors\", ylim = c(-10, 10)),\n    qqnorm(resid, main = \"Q-Q plot to test normality of errors\"),\n    pairs(data, main = \"Assessing Linearity of\\n Predictors with Outcome\")\n  )\n  impl &lt;- data.frame(\n    Estimate = estimate,\n    Std.Error = se,\n    t.value = t,\n    p.value = p,\n    Residual = c(residual, rep(NA, ncol(X) - 1)),\n    DegOfFreedom = c(df, rep(NA, ncol(X) - 1)),\n    row.names = c(\"(Intercept)\", paste0(rep(\"x\", ncol(\n      X\n    ) - 1), rownames))\n  )\n  # returning a data frame akin to the lm output\n  return(list(test, impl))\n}\n\nCreating a test data set which meets all Linear Regression assumptions to check if our function works.\n\ntest_linear_regression_data &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- rnorm(100, mean = 0, sd = 1) # errors are homoscedastic\ntest_linear_regression_data$y &lt;-\n  2 * test_linear_regression_data$x1 +\n  0.2 * test_linear_regression_data$x2 + error\n\nplot(test_linear_regression_data$x1, test_linear_regression_data$y,\n  xlab = \"x1\", ylab = \"y\",\n  main = \"Outcome is linear to x1\"\n)\n\n\n\n\n\n\n\nplot(test_linear_regression_data$x2, test_linear_regression_data$y,\n  xlab = \"x2\", ylab = \"y\",\n  main = \"Outcome is linear to x2 (it is not apparent in this plot but our data structure captures this relationship)\", cex.main = 0.6\n)\n\n\n\n\n\n\n\nplot(density(error), main = \"Errors are normally distributed with mean 0\")\n\n\n\n\n\n\n\nplot(error,\n  ylab = \"residuals\", main = \"Residuals are homoscedastic\", ylim = c(-3, 3)\n)"
  },
  {
    "objectID": "regressions/linear.html#testing-assumptions-for-linear-regression",
    "href": "regressions/linear.html#testing-assumptions-for-linear-regression",
    "title": "Linear",
    "section": "Testing Assumptions for Linear Regression",
    "text": "Testing Assumptions for Linear Regression\n\nour_implementation &lt;- linear_regression(\n  test_linear_regression_data,\n  test_linear_regression_data$x1,\n  test_linear_regression_data$x2,\n  y = test_linear_regression_data$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation\n\n             Estimate  Std.Error   t.value      p.value  Residual DegOfFreedom\n(Intercept) 0.4679943 0.31344739  1.493055 1.386684e-01 0.9369198           97\nx1          1.9334142 0.05792076 33.380331 5.582525e-55        NA           NA\nx2          0.2119056 0.05038448  4.205772 5.802633e-05        NA           NA\n\n\nComparing our output to R’s output.\n\nr_implementation &lt;-\n  summary(lm(y ~ x1 + x2, data = test_linear_regression_data))\nr_implementation\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = test_linear_regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8730 -0.6607 -0.1245  0.6214  2.0798 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.46799    0.28753   1.628    0.107    \nx1           1.93341    0.05243  36.873  &lt; 2e-16 ***\nx2           0.21191    0.04950   4.281 4.37e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9513 on 97 degrees of freedom\nMultiple R-squared:  0.9337,    Adjusted R-squared:  0.9323 \nF-statistic: 682.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nWe note that the results are similar.\nWe followed all assumptions of Linear Regression in regressing y on x1 and x2 using the test_linear_regression_data data set. We will compare the residual of this regression to that of all the others where assumptions will be broken.\nThe residual for where all assumptions are met:\n\nour_implementation$Residual[1] # a small residual here\n\n[1] 0.9369198"
  },
  {
    "objectID": "regressions/linear.html#breaking-assumptions",
    "href": "regressions/linear.html#breaking-assumptions",
    "title": "Linear",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nBreaking the assumption of the predictors and outcome following a linear relationship\nCreating a data set where, if we apply linear regression, this assumption will be broken.\n\ntest_linear_regression_data_not_linear &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- rnorm(100, mean = 0, sd = 1)\ntest_linear_regression_data_not_linear$y &lt;-\n  2 * test_linear_regression_data_not_linear$x1^2 + 0.2 *\n    test_linear_regression_data_not_linear$x2^2 + error\n\nplot(test_linear_regression_data_not_linear$x1, test_linear_regression_data_not_linear$y,\n  xlab = \"x1\", ylab = \"y\",\n  main = \"Outcome is not linear to x1\"\n)\n\n\n\n\n\n\n\nplot(test_linear_regression_data_not_linear$x2, test_linear_regression_data_not_linear$y,\n  xlab = \"x2\", ylab = \"y\",\n  main = \"Outcome is not linear to x2\"\n)\n\n\n\n\n\n\n\n\nUsing our implementation of Linear Regression to fit the model.\n\nour_implementation_not_linear &lt;- linear_regression(\n  test_linear_regression_data_not_linear,\n  test_linear_regression_data_not_linear$x1,\n  test_linear_regression_data_not_linear$x2,\n  y = test_linear_regression_data_not_linear$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation_not_linear$Residual[1] # a higher residual here\n\n[1] 10.22817\n\n\nWe note that linear regression is not performing as well in this case.\n\n\nBreaking the assumption of the errors being normally distributed\nCreating a data set where, if we apply linear regression, this assumption will be broken.\n\ntest_linear_regression_data_not_normally_dist &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- runif(100, min = 0, max = 5)\ntest_linear_regression_data_not_normally_dist$y &lt;-\n  2 * test_linear_regression_data_not_normally_dist$x1 + 0.2 *\n    test_linear_regression_data_not_normally_dist$x2 + error\n\nplot(density(error), main = \"Errors are not normally distributed\")\n\n\n\n\n\n\n\n\nUsing our implementation of lm to fit the model.\n\nour_implementation_not_normally_dist &lt;- linear_regression(\n  test_linear_regression_data_not_normally_dist,\n  test_linear_regression_data_not_normally_dist$x1,\n  test_linear_regression_data_not_normally_dist$x2,\n  y = test_linear_regression_data_not_normally_dist$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation_not_normally_dist$Residual[1] # a higher residual here\n\n[1] 1.414274\n\n\nWe note that linear regression is not performing as well in this case.\n\n\nBreaking the assumption of the errors being homoscedastic\nCreating a data set where, if we apply linear regression, this assumption will be broken.\n\ntest_linear_regression_data_not_homoscedastic &lt;-\n  data.frame(\n    x1 = rnorm(100, mean = 5, sd = 2),\n    x2 = rnorm(100, mean = 0, sd = 2)\n  )\nerror &lt;- c(\n  rnorm(50, mean = 0, sd = 1),\n  rnorm(50, mean = 0, sd = 10)\n)\ntest_linear_regression_data_not_homoscedastic$y &lt;-\n  2 * test_linear_regression_data_not_homoscedastic$x1 + 0.2 *\n    test_linear_regression_data_not_homoscedastic$x2 + error\n\nplot(error,\n  ylab = \"error\", main = \"Residuals are not homoscedastic\", ylim = c(-20, 20)\n)\n\n\n\n\n\n\n\n\nUsing our implementation of lm to fit the model.\n\nour_implementation_not_homoscedastic &lt;- linear_regression(\n  test_linear_regression_data_not_homoscedastic,\n  test_linear_regression_data_not_homoscedastic$x1,\n  test_linear_regression_data_not_homoscedastic$x2,\n  y = test_linear_regression_data_not_homoscedastic$y\n)[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nour_implementation_not_homoscedastic$Residual[1] # a higher residual here\n\n[1] 6.419781\n\n\nWe note that linear regression is not performing as well in this case."
  },
  {
    "objectID": "regressions/linear.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "href": "regressions/linear.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "title": "Linear",
    "section": "Comparing residuals when all assumptions were met versus not",
    "text": "Comparing residuals when all assumptions were met versus not\n\nresidual_comparison &lt;-\n  t(\n    data.frame(\n      resid_all_assumptions_met = our_implementation$Residual[1],\n      resid_not_linear = our_implementation_not_linear$Residual[1],\n      resid_not_normally_dist = our_implementation_not_normally_dist$Residual[1],\n      resid_not_homoscedastic = our_implementation_not_homoscedastic$Residual[1]\n    )\n  )\nrow.names(residual_comparison) &lt;- c(\n  \"All assumptions met\",\n  \"Linearity assumption violated\",\n  \"Normality assumption violated\",\n  \"Homoscedasticity assumption violated\"\n)\ncolnames(residual_comparison) &lt;- \"Residuals\"\nresidual_comparison\n\n                                      Residuals\nAll assumptions met                   0.9369198\nLinearity assumption violated        10.2281685\nNormality assumption violated         1.4142737\nHomoscedasticity assumption violated  6.4197814"
  },
  {
    "objectID": "regressions/linear.html#conclusion",
    "href": "regressions/linear.html#conclusion",
    "title": "Linear",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation of Linear Regression where all assumptions are met performs the best; i.e. it gives us predictions which are closest to the true outcome values. From the residual comparison, we also note that applying linear regression to data that aren’t linear can be especially worrisome."
  },
  {
    "objectID": "regressions/poisson.html",
    "href": "regressions/poisson.html",
    "title": "Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data. We use Poisson distribution to model the expected value of \\(Y\\), which is denoted by \\(E(Y) = \\mu\\). The identity link is the log link, so the Poisson regression model for counts is \\(log(\\mu) = \\alpha + \\beta x\\). The Poisson distribution with parameter \\(\\lambda\\), \\(Poi(\\lambda)\\) has the probability mass function\n\\[\nP(X=k) = exp(-\\lambda)\\frac{\\lambda^k}{k!}, k=0,1,2,3,...\n\\]"
  },
  {
    "objectID": "regressions/poisson.html#introduction",
    "href": "regressions/poisson.html#introduction",
    "title": "Poisson",
    "section": "",
    "text": "Poisson regression is used for count and rate data. We use Poisson distribution to model the expected value of \\(Y\\), which is denoted by \\(E(Y) = \\mu\\). The identity link is the log link, so the Poisson regression model for counts is \\(log(\\mu) = \\alpha + \\beta x\\). The Poisson distribution with parameter \\(\\lambda\\), \\(Poi(\\lambda)\\) has the probability mass function\n\\[\nP(X=k) = exp(-\\lambda)\\frac{\\lambda^k}{k!}, k=0,1,2,3,...\n\\]"
  },
  {
    "objectID": "regressions/poisson.html#uses",
    "href": "regressions/poisson.html#uses",
    "title": "Poisson",
    "section": "Uses",
    "text": "Uses\nPoisson regression can be used for count data, such as number of asthmatic attacks in one year based on the number of hospital admissions and systolic blood pressure. When the predictor variables are continuous, poisson regression ensures that the outcome variable is positive, compared to a linear regression which might predict negative counts. Another use case for Poisson regression is when the number of cases is small relative to the number of no events, such as when the number of deaths due to COVID-19 are small relative to the total population size. Logistic regression is more useful when we have data on both the binary outcomes (e.g. death and non-deaths)."
  },
  {
    "objectID": "regressions/poisson.html#assumptions",
    "href": "regressions/poisson.html#assumptions",
    "title": "Poisson",
    "section": "Assumptions",
    "text": "Assumptions\n\noutcome variable must be count data\nIndependent observations\nDistribution of counts follow a Poisson distribution\nNo overdispersion - the mean and variance of the distribution are equal. If the variance is greater than the mean, negative binomial regression may be more appropriate"
  },
  {
    "objectID": "regressions/poisson.html#our-poisson-regression-implementation",
    "href": "regressions/poisson.html#our-poisson-regression-implementation",
    "title": "Poisson",
    "section": "Our Poisson Regression Implementation",
    "text": "Our Poisson Regression Implementation\n\npoisson_function &lt;- function(fn_formula, data, predict = F) {\n  number_omitted &lt;- nrow(data) - nrow(na.omit(data))\n  data &lt;- na.omit(data)\n\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  x_name &lt;- vars[2:length(vars)]\n  n &lt;- nrow(data)\n  Y &lt;- matrix(data[, y_name], nrow = n, ncol = 1)\n  X &lt;- matrix(cbind(rep(1, n)))\n\n  # take in categorical data\n  var_names &lt;- vector(\"character\")\n  for (i in x_name) {\n    if (suppressWarnings(all(!is.na(as.numeric(as.character(data[, i])))))) {\n      X &lt;- cbind(X, as.numeric(as.character(data[, i])))\n      var_names &lt;- c(var_names, i)\n    } else {\n      categories &lt;- sort(unique(data[, i]))\n      for (j in categories[2:length(categories)]) {\n        new_col_name &lt;- paste0(i, j)\n        new_col &lt;- ifelse(data[, i] == j, 1, 0)\n        X &lt;- cbind(X, new_col)\n        var_names &lt;- c(var_names, new_col_name)\n      }\n    }\n  }\n  optim_poisson &lt;- function(beta, X, Y) {\n    beta &lt;- as.matrix(beta, nrow = 4)\n    beta_x &lt;- X %*% beta\n    loglikelihood &lt;- -sum(Y * beta_x - exp(beta_x))\n    return(loglikelihood)\n  }\n  result &lt;- optim(par = rep(0, ncol(X)), fn = optim_poisson, X = X, Y = Y, hessian = T)\n  OI &lt;- solve(result$hessian)\n  se &lt;- sqrt(diag(OI))\n  z_value &lt;- result$par / se\n  df &lt;- nrow(X) - ncol(X)\n  p_value &lt;- 2 * pnorm(-1 * abs(z_value))\n\n  coef &lt;- rbind(result$par, se, z_value, p_value)\n  colnames(coef) &lt;- c(\"(Intercept)\", var_names)\n  rownames(coef) &lt;- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n\n  b_hat &lt;- result$par\n  predictions &lt;- exp(X %*% b_hat)\n\n  if (predict) {\n    return(predictions)\n  } else {\n    return(t(coef))\n  }\n}\n\nTesting poisson implementation with simulated data\n\nn &lt;- 100\nx1 &lt;- sample(0:1, n, replace = T)\nlambda &lt;- exp(2 + 0.5 * x1)\ny &lt;- rpois(n, lambda)\nsim_data &lt;- data.frame(y, x1)\nm1 &lt;- glm(y ~ x1, family = poisson, data = sim_data)\nsummary(m1)$coef\n\n             Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) 1.9948197 0.04885319 40.832944 0.000000e+00\nx1          0.5035617 0.06556432  7.680423 1.585642e-14\n\npoisson_function(fn_formula = \"y ~ x1\", data = sim_data)\n\n             Estimate Std. Error  z value      p value\n(Intercept) 1.9947730 0.04885433 40.83104 0.000000e+00\nx1          0.5036104 0.06556513  7.68107 1.577649e-14\n\nggplot(sim_data) +\n  geom_histogram(aes(x = y, fill = factor(x1))) +\n  facet_wrap(~x1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nShow that our implementation of poisson regression can also make predictions\n\nidx &lt;- sample(1:n, 5)\np1 &lt;- poisson_function(fn_formula = \"y ~ x1\", data = sim_data, predict = T)[idx]\np2 &lt;- predict(m1, type = \"response\")[idx]\n\ncompare_predict_data &lt;- data.frame(p1, p2)\ncolnames(compare_predict_data) &lt;- c(\"Our implementation\", \"GLM\")\n\nkable(compare_predict_data, digits = 3, caption = \"Comparison of Poisson prediction\", booktabs = TRUE, valign = \"t\") |&gt; kable_styling(latex_options = \"HOLD_position\")\n\n\nComparison of Poisson prediction\n\n\n\nOur implementation\nGLM\n\n\n\n\n7\n12.163\n12.163\n\n\n100\n7.351\n7.351\n\n\n58\n7.351\n7.351\n\n\n61\n7.351\n7.351\n\n\n74\n7.351\n7.351\n\n\n\n\n\n\n\nTesting poisson implementation with crabs data\n\n# comparing coefficients with crabs data\ndata(crabs, package = \"glmbb\")\nsummary(glm(satell ~ width, family = poisson(link = \"log\"), data = crabs))$coef\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -3.3047572 0.54224155 -6.094622 1.096964e-09\nwidth        0.1640451 0.01996535  8.216491 2.095450e-16\n\n# a bit over-dispersed\nmean(crabs$satell)\n\n[1] 2.919075\n\nvar(crabs$satell)\n\n[1] 9.912018\n\npoisson_function(fn_formula = \"satell ~ width\", data = crabs)\n\n              Estimate Std. Error   z value      p value\n(Intercept) -3.3041041 0.54211127 -6.094882 1.095184e-09\nwidth        0.1640204 0.01995812  8.218226 2.065351e-16\n\nggplot(crabs) +\n  geom_histogram(aes(x = satell),\n    binwidth = 1,\n    fill = \"forestgreen\", color = \"gray\"\n  )\n\n\n\n\n\n\n\n\nInterpretation of coefficients\nA change in 1 unit of width has a multiplicative effect on the mean of \\(Y\\). For a 1 unit increase in log(width), the estimated mean number of satellites increases by a factor of \\(e^{0.164} = 1.178\\) when the log linear model is \\(log(\\mu_i) = -3.3 + 0.164 * width_i\\)."
  },
  {
    "objectID": "regressions/poisson.html#breaking-assumptions",
    "href": "regressions/poisson.html#breaking-assumptions",
    "title": "Poisson",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nIndependent observations\n\nn &lt;- 100\nx1 &lt;- sample(0:5, n, replace = T)\nlambda &lt;- exp(1.5 + 0.5 * x1)\ny &lt;- rpois(n, lambda)\nsim_data &lt;- data.frame(y, x1)\nmp &lt;- glm(y ~ x1, data = sim_data, family = poisson)\nplot(mp, which = 1)\n\n\n\n\n\n\n\nmp &lt;- glm(satell ~ width, data = crabs, family = poisson)\nplot(mp, which = 1)\n\n\n\n\n\n\n\n\nCreating fake data that has good residuals vs crabs data which has a fitted line that is not at zero. It is easy to think about why the observations may not be independent for the crabs data, if a few are observed in clusters of units, or in certain ecologies.\n\n\nDistribution of counts follow a Poisson distribution\n\nn &lt;- 100\nx1 &lt;- runif(n, 0, 10)\nx2 &lt;- runif(n, -10, 0)\nlambda &lt;- exp(1.5 + 0.5 * x1 + 0.5 * x2)\ny &lt;- rpois(n, lambda)\ngood_data &lt;- data.frame(y, x1, x2)\nlog.lambda &lt;- log(poisson_function(fn_formula = \"y ~ x1 + x2\", data = good_data, predict = T))\nplot_data &lt;- data.frame(log.lambda, x1, x2) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# show non-linear data\nn &lt;- 100\nx1 &lt;- runif(n, 0, 10)\nx2 &lt;- runif(n, -10, 0)\nlambda &lt;- exp(0.5 * x1^2 + 0.5 * x1 * x2)\ny &lt;- rpois(n, lambda)\nworse_data &lt;- data.frame(y, x1, x2)\nlog.lambda &lt;- log(poisson_function(fn_formula = \"y ~ x1 + x2\", data = worse_data, predict = T))\nplot_data &lt;- data.frame(log.lambda, x1, x2) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# show for binary x1\nn &lt;- 100\nx1 &lt;- sample(0:1, n, replace = T)\nlambda &lt;- exp(2 + 0.5 * x1)\ny &lt;- rpois(n, lambda)\nsim_data &lt;- data.frame(y, x1)\nlog.lambda &lt;- log(poisson_function(fn_formula = \"y ~ x1\", data = sim_data, predict = T))\nplot_data &lt;- data.frame(log.lambda, x1) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -log.lambda)\n\nggplot(plot_data, aes(x = log.lambda, y = predictor_value)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  theme_bw() +\n  facet_wrap(~predictors, scales = \"free_y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDoes the Poisson distribution predict well? We want to see a linear relationship between \\(log(\\lambda)\\) and each predictor variable. This will only be visible for continuous predictor data.\n\n\nNo overdispersion - the mean and variance of the distribution are equal\nOne of the main assumptions for Poisson regression is that the mean and variance are equal. When the variance is larger than the mean, there is overdispersion. This can be formally tested using the the overdispersion parameter.\n\ndata(crabs, package = \"glmbb\")\nM1 &lt;- glm(satell ~ width, family = poisson(link = \"log\"), data = crabs)\nM2 &lt;- glm.nb(satell ~ width, data = crabs)\nM3 &lt;- pscl::zeroinfl(satell ~ width | width, data = crabs)\n# estimate overdispersion\nestimate_overdisp &lt;- function(model_obj, data) {\n  z &lt;- resid(model_obj, type = \"pearson\")\n  n &lt;- nrow(data)\n  k &lt;- length(coef(model_obj))\n  overdisp_ratio &lt;- sum(z^2) / (n - k)\n  p_val &lt;- pchisq(sum(z^2), (n - k))\n  return(cat(\"overdispersion ratio: \", overdisp_ratio, \"\\n\", \"p-value:\", p_val, \"\\n\"))\n}\nestimate_overdisp(M1, crabs)\n\noverdispersion ratio:  3.182205 \n p-value: 1 \n\nestimate_overdisp(M2, crabs)\n\noverdispersion ratio:  0.8464955 \n p-value: 0.07176482 \n\nestimate_overdisp(M3, crabs)\n\noverdispersion ratio:  1.349534 \n p-value: 0.9983357 \n\n\nThe estimated overdispersion for the crabs data is 3.18, which is large, and has a p-value of 1, which indicates that the probability is essentially zero that a random variable from the distribution would be so large. When the negative binomial model is fitted, the crabs data has an estimated overdispersion of 0.85, with a smaller p-value. It is still overdispersed relative to a negative binomial distribution, but to a smaller scale than it was to a Poisson distribution."
  },
  {
    "objectID": "regressions/poisson.html#conclusion",
    "href": "regressions/poisson.html#conclusion",
    "title": "Poisson",
    "section": "Conclusion",
    "text": "Conclusion\nMeeting the assumptions for a Poisson regression, particularly for dispersion, is quite difficult, even when simulating data. It is unclear when the mean and variance of a distribution might happen to be naturally the same."
  },
  {
    "objectID": "regressions/logistic.html",
    "href": "regressions/logistic.html",
    "title": "Logistic",
    "section": "",
    "text": "Logistic regression is used when the outcome variable is discrete and binary, which is called classification. Multinomial logistic regression can classify observations into more than two categories, but we are only doing simple logistic regression here, with two categories. We use the inverse logit function to model the probability that \\(Y_i = 1\\).\n\\[\nlogit^{-1}(x)=\\frac{e^x}{1+e^x} \\\\\nPr(y_i=1) = logit^{-1}(X_i\\beta)\n\\]plogis is the invlogit function."
  },
  {
    "objectID": "regressions/logistic.html#introduction",
    "href": "regressions/logistic.html#introduction",
    "title": "Logistic",
    "section": "",
    "text": "Logistic regression is used when the outcome variable is discrete and binary, which is called classification. Multinomial logistic regression can classify observations into more than two categories, but we are only doing simple logistic regression here, with two categories. We use the inverse logit function to model the probability that \\(Y_i = 1\\).\n\\[\nlogit^{-1}(x)=\\frac{e^x}{1+e^x} \\\\\nPr(y_i=1) = logit^{-1}(X_i\\beta)\n\\]plogis is the invlogit function."
  },
  {
    "objectID": "regressions/logistic.html#uses",
    "href": "regressions/logistic.html#uses",
    "title": "Logistic",
    "section": "Uses",
    "text": "Uses\nLogistic regression is good for when covariates are continuous, as the outcome variables are bounded between 0 and 1, through the logit link."
  },
  {
    "objectID": "regressions/logistic.html#assumptions",
    "href": "regressions/logistic.html#assumptions",
    "title": "Logistic",
    "section": "Assumptions",
    "text": "Assumptions\n\nFor binary logistic regression, that outcome variables are binary\nIndependence of errors\nLinear relationship between the outcome variable and log odds of the predictor variables\nNo multicollinearity"
  },
  {
    "objectID": "regressions/logistic.html#our-logistic-regression-implementation",
    "href": "regressions/logistic.html#our-logistic-regression-implementation",
    "title": "Logistic",
    "section": "Our Logistic Regression Implementation",
    "text": "Our Logistic Regression Implementation\n\nlibrary(alr4)\n# invlogit &lt;- plogis\n\nlogistic_function &lt;- function(fn_formula, data, predict = F) {\n  number_omitted &lt;- nrow(data) - nrow(na.omit(data))\n  data &lt;- na.omit(data)\n\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  x_name &lt;- vars[2:length(vars)]\n  n &lt;- nrow(data)\n  Y &lt;- matrix(data[, y_name], nrow = n, ncol = 1)\n  X &lt;- matrix(cbind(rep(1, n)))\n\n  # take in categorical data\n  var_names &lt;- vector(\"character\")\n  for (i in x_name) {\n    if (suppressWarnings(all(!is.na(as.numeric(as.character(data[, i])))))) {\n      X &lt;- cbind(X, as.numeric(as.character(data[, i])))\n      var_names &lt;- c(var_names, i)\n    } else {\n      categories &lt;- sort(unique(data[, i]))\n      for (j in categories[2:length(categories)]) {\n        new_col_name &lt;- paste0(i, j)\n        new_col &lt;- ifelse(data[, i] == j, 1, 0)\n        X &lt;- cbind(X, new_col)\n        var_names &lt;- c(var_names, new_col_name)\n      }\n    }\n  }\n  optim_logistic &lt;- function(beta, X, Y) {\n    beta &lt;- as.matrix(beta, nrow = 4)\n    pi &lt;- plogis(X %*% beta)\n    loglikelihood &lt;- -sum(Y * log(pi) + (1 - Y) * log(1 - pi))\n    return(loglikelihood)\n  }\n  result &lt;- optim(par = rep(0, ncol(X)), fn = optim_logistic, X = X, Y = Y, hessian = T)\n  OI &lt;- solve(result$hessian)\n  se &lt;- sqrt(diag(OI))\n  t_statistic &lt;- result$par / se\n  df &lt;- nrow(X) - ncol(X)\n  p_value &lt;- 2 * pnorm(-1 * abs(t_statistic))\n  # https://stats.stackexchange.com/questions/52475/how-are-the-p-values-of-the-glm-in-r-calculated\n\n  coef &lt;- rbind(result$par, se, t_statistic, p_value)\n  colnames(coef) &lt;- c(\"(Intercept)\", var_names)\n  rownames(coef) &lt;- c(\"Estimate\", \"Std. Error\", \"z value\", \"p value\")\n  coef &lt;- t(coef)\n\n  b_hat &lt;- result$par\n  predictions &lt;- plogis(X %*% b_hat)\n\n  if (predict) {\n    return(predictions)\n  } else {\n    return(coef)\n  }\n}\n\nCreating testing data set with a single predictor variable to compare our implementation with glm logistic function\n\n# create fake data\nx1 &lt;- rnorm(100, 2, 1)\nprob &lt;- plogis(-1 + 0.5 * x1)\ny &lt;- rbinom(100, 1, prob)\nsim_data &lt;- data.frame(y, x1)\n\n# compare DIY logistic function with glm\nfit_sim_data_1 &lt;- glm(y ~ x1, data = sim_data, family = binomial)\nsummary(fit_sim_data_1)$coef\n\n              Estimate Std. Error   z value   Pr(&gt;|z|)\n(Intercept) -0.7456721  0.5316508 -1.402560 0.16074811\nx1           0.5410003  0.2427422  2.228703 0.02583366\n\nlogistic_function(fn_formula = \"y ~ x1\", data = sim_data)\n\n              Estimate Std. Error   z value    p value\n(Intercept) -0.7459709  0.5316604 -1.403097 0.16058801\nx1           0.5410940  0.2427464  2.229051 0.02581053\n\n# checking for linear relationship\nplot(sim_data$x1, prob,\n  main = \"The log odds of y and x1 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\n# check for correlation of residuals vs fit\nplot(fit_sim_data_1, which = 1)\n\n\n\n\n\n\n\n\nCreating testing data set with multiple covariates to compare our implementation with glm logistic function\n\n# create fake data with multiple x's\nx1 &lt;- rnorm(100, 2, 1)\nx2 &lt;- rnorm(100, 4, 1)\nx3 &lt;- rnorm(100, 6, 1)\nprob &lt;- plogis(-1 + x1 + x2 - 0.5 * x3)\ny &lt;- rbinom(100, 1, prob)\nsim_data &lt;- data.frame(y, x1, x2, x3)\n\n# compare DIY logistic function with glm\nfit_sim_data &lt;- glm(y ~ x1 + x2 + x3, data = sim_data, family = binomial)\nsummary(fit_sim_data)$coef\n\n              Estimate Std. Error    z value    Pr(&gt;|z|)\n(Intercept)  2.4011218  2.4617714  0.9753634 0.329380012\nx1           1.3097873  0.4646174  2.8190663 0.004816356\nx2           0.9528707  0.3591008  2.6534911 0.007966387\nx3          -1.1133007  0.3837826 -2.9008631 0.003721364\n\nlogistic_function(fn_formula = \"y ~ x1 + x2 + x3\", data = sim_data)\n\n              Estimate Std. Error    z value     p value\n(Intercept)  2.4003220  2.4618335  0.9750139 0.329553343\nx1           1.3102691  0.4646817  2.8197132 0.004806659\nx2           0.9530523  0.3591195  2.6538587 0.007957715\nx3          -1.1134496  0.3838115 -2.9010321 0.003719358\n\n\nUsing the alr4 Donner data to test categorical data, and compare our implementation with glm logistic function\n\nDonner$survived &lt;- Donner$y == \"survived\"\nfit_Donner &lt;- glm(survived ~ age + sex + status, data = Donner, family = \"binomial\")\nsummary(fit_Donner)$coef\n\n                Estimate   Std. Error      z value    Pr(&gt;|z|)\n(Intercept)    1.4873491 4.926432e-01  3.019120666 0.002535095\nage           -0.0281043 1.504262e-02 -1.868311545 0.061718658\nsexMale       -0.7279889 5.172218e-01 -1.407498622 0.159279585\nstatusHired   -0.5985928 6.281956e-01 -0.952876467 0.340652665\nstatusSingle -17.4555740 1.765537e+03 -0.009886838 0.992111573\n\nlogistic_function(fn_formula = \"survived ~ age + sex + status\", data = Donner)\n\n                Estimate  Std. Error    z value     p value\n(Intercept)   1.50395496  0.49431184  3.0425226 0.002346042\nage          -0.02838637  0.01507534 -1.8829672 0.059704810\nsexMale      -0.74855738  0.51805480 -1.4449386 0.148475138\nstatusHired  -0.58665853  0.62833280 -0.9336748 0.350471646\nstatusSingle -6.48117449 12.14886686 -0.5334798 0.593701523\n\n\nInterpretation of the coefficients\nA 1-unit difference in age corresponds to -0.02 in the logit probability of having survived in the Donner party, or a multiplicative change of \\(e^{-0.0283}=0.972\\) in the odds of surviving.\n\nggplot(Donner) +\n  geom_jitter(aes(x = age, y = survived, color = survived)) +\n  facet_wrap(vars(status)) +\n  ggtitle(\"Younger people generally had a higher chance of surviving\")\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nShow that our implementation of logistic regression can also make predictions\n\nidx &lt;- sample(1:nrow(Donner), 5)\np1 &lt;- logistic_function(fn_formula = \"survived ~ age + sex + status\", data = Donner, predict = T)[idx, ]\np2 &lt;- predict(fit_Donner, type = \"response\")[idx]\ncompare_predict_data &lt;- data.frame(p1, p2)\ncolnames(compare_predict_data) &lt;- c(\"Our implementation\", \"GLM\")\n\nkable(compare_predict_data, digits = 3, caption = \"Comparison of logistic prediction\", booktabs = TRUE, valign = \"t\") |&gt; kable_styling(latex_options = \"HOLD_position\")\n\n\nComparison of logistic prediction\n\n\n\nOur implementation\nGLM\n\n\n\n\nBreen_Margaret_Isabella\n0.814\n0.811\n\n\nBreen_Patrick\n0.334\n0.338\n\n\nSpitzer_Augustus\n0.001\n0.000\n\n\nDonner_Isaac\n0.649\n0.650\n\n\nFoster_Sarah_Ann_Charlotte_Murphy\n0.724\n0.722"
  },
  {
    "objectID": "regressions/logistic.html#function-to-check-assumptions",
    "href": "regressions/logistic.html#function-to-check-assumptions",
    "title": "Logistic",
    "section": "Function to check assumptions",
    "text": "Function to check assumptions\n\ntest_logistic_assumptions &lt;- function(fn_formula, data) {\n  n &lt;- nrow(data)\n  vars &lt;- all.vars(as.formula(fn_formula))\n  y_name &lt;- vars[1]\n  Y &lt;- data[, y_name]\n\n  # outcome variables are binary\n  if (length(unique(Y)) == 2) {\n    assp_1 &lt;- paste(\"Binary outcomes assumption is met.\")\n  } else {\n    return(paste(\"Binary outcomes assumption is not satisfied. There are\", length(unique(Y)), \"outcomes.\"))\n  }\n\n  x_name &lt;- vars[2:length(vars)]\n  X &lt;- data[, x_name]\n  preds &lt;- logistic_function(fn_formula = fn_formula, data = data, predict = T) # predictions are in probability\n  logit_vals &lt;- log(preds / (1 - preds))\n  plot_data &lt;- data.frame(logit_vals, X) |&gt; gather(key = \"predictors\", value = \"predictor_value\", -logit_vals)\n\n  # Linear relationship between the outcome variable and log odds of the predictor variables\n  assp_2 &lt;- ggplot(plot_data, aes(logit_vals, predictor_value)) +\n    geom_point(size = 0.5, alpha = 0.5) +\n    geom_smooth(method = \"loess\") +\n    theme_bw() +\n    facet_wrap(~predictors, scales = \"free_y\")\n\n  # Independence of errors\n  # plot residuals vs fits\n  model &lt;- glm(fn_formula, data = data, family = binomial)\n  assp_3 &lt;- plot(model, which = 1)\n\n  # No multicollinearity\n  assp_4 &lt;- cor(data[, -1])\n\n  predicted.values &lt;- ifelse(preds &gt;= 0.5, 1, 0)\n  check_perf &lt;- data.frame(Y, predicted.values) |&gt; mutate(correct = Y == predicted.values)\n  check_perf &lt;- paste0(mean(check_perf$correct) * 100, \"% classified correctly\")\n  return(list(assp_1, assp_2, print(assp_3), assp_4, check_perf))\n}\n\nn &lt;- 200\nx1 &lt;- rnorm(n, 2, 1)\nx2 &lt;- rnorm(n, 4, 1)\nprob &lt;- plogis(-1 + 1.2 * x1 - 0.5 * x2)\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nsim_data &lt;- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = sim_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n          x1        x2\nx1  1.000000 -0.018217\nx2 -0.018217  1.000000\n\n[[5]]\n[1] \"78.5% classified correctly\"\n\n\n\nFor binary logistic regression, that outcome variables are binary\nCheck how many unique outcome variables there are.\nIndependence of errors\nCheck residual plots.\nLinear relationship between the outcome variable and log odds of the predictor variables\nCheck scatterplots of log odds vs predictor variables to see that there is an approximately linear relationship.\nNo multicollinearity\nLook at the correlation matrix, generally any value over 0.9 is problematic."
  },
  {
    "objectID": "regressions/logistic.html#breaking-assumptions",
    "href": "regressions/logistic.html#breaking-assumptions",
    "title": "Logistic",
    "section": "Breaking assumptions",
    "text": "Breaking assumptions\n\n1. For binary logistic regression, that outcome variables are binary\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 2, 1)\nprob &lt;- plogis(-1 + 0.8 * x1)\ny &lt;- rpois(n, prob)\nbad_data &lt;- data.frame(y, x1)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1\", data = bad_data)\n\n[1] \"Binary outcomes assumption is not satisfied. There are 4 outcomes.\"\n\n\n\n\n2. Independence of errors\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 2, 1)\nx2 &lt;- rnorm(n, 0, 1)\nprob &lt;- plogis(-1.2 + 0.4 * x1 + 0.3 * x2 + rbeta(n, 2, 2))\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nbad_data &lt;- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = bad_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n           x1         x2\nx1 1.00000000 0.09361225\nx2 0.09361225 1.00000000\n\n[[5]]\n[1] \"62% classified correctly\"\n\n\nI used rbeta to introduce more error for the middle of the probabilities, which shows in the residual plot, where it looks like there is a peak in the fitted line around 0.\n\n\n3. Linear relationship between the outcome variable and log odds of the predictor variables\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 0, 1)\nx2 &lt;- rnorm(n, 2, 1)\nx3 &lt;- rnorm(n, -2, 1)\nprob &lt;- plogis(-1 + x1 * x2 + 1.3 * x2 - 0.5 * x3^2)\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nbad_data &lt;- data.frame(y, x1, x2, x3)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2 + x3\", data = bad_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n           x1          x2          x3\nx1  1.0000000 -0.16860022 -0.17308515\nx2 -0.1686002  1.00000000  0.02992617\nx3 -0.1730851  0.02992617  1.00000000\n\n[[5]]\n[1] \"82% classified correctly\"\n\n\nFor the probability used in the DGP, it is no longer a linear relationship of \\(X_i\\beta\\) but one that involves interactions and squared variables. The non-linear relationship is visible in the plots of the outcome variable vs log odds of each predictor variable.\n\n\n4. No multicollinearity\n\nn &lt;- 100\nx1 &lt;- rnorm(n, 0, 1)\nx2 &lt;- rnorm(n, x1, 0.2)\nprob &lt;- plogis(-1 + x1 + 0.5 * x2)\nhist(prob)\n\n\n\n\n\n\n\ny &lt;- rbinom(n, 1, prob)\nbad_data &lt;- data.frame(y, x1, x2)\n\ntest_logistic_assumptions(fn_formula = \"y ~ x1 + x2\", data = bad_data)\n\n\n\n\n\n\n\n\nNULL\n\n\n[[1]]\n[1] \"Binary outcomes assumption is met.\"\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n[[3]]\nNULL\n\n[[4]]\n          x1        x2\nx1 1.0000000 0.9847734\nx2 0.9847734 1.0000000\n\n[[5]]\n[1] \"80% classified correctly\"\n\n\nThe DGP involves \\(x2\\) being created from an rnorm around the mean of \\(x1\\), and a small SD so that it is even more correlated. The correlation matrix shows a problematically high correlation. The model still classifies fairly well, but what happens with multicollinearity is that it becomes difficult for the model to estimate the relationship between each predictor variable and the outcome variable independently because the predictor variables tend to change in unison. The p-values are also less trustworthy."
  },
  {
    "objectID": "regressions/logistic.html#next-steps",
    "href": "regressions/logistic.html#next-steps",
    "title": "Logistic",
    "section": "Next Steps",
    "text": "Next Steps\n\nInstead of just using maximum likelihood, we could try using iteratively reweighted least squares or Newton-Ralphson."
  },
  {
    "objectID": "regressions/logistic.html#conclusion",
    "href": "regressions/logistic.html#conclusion",
    "title": "Logistic",
    "section": "Conclusion",
    "text": "Conclusion\nBreaking certain assumptions do not make the logistic model classify worse. Independence of errors seems to be the worst case, but the rest do not change the correct classification rate much."
  },
  {
    "objectID": "regressions/negative-binomial.html",
    "href": "regressions/negative-binomial.html",
    "title": "Negative Binomial",
    "section": "",
    "text": "Negative Binomial Regression is used for predicting count data, similar to Poisson Regression, but the Negative Binomial is more flexible as it allows for the variance of the outcome to be greater than its mean (in Poisson Regression, they are assumed to be equal)."
  },
  {
    "objectID": "regressions/negative-binomial.html#introduction",
    "href": "regressions/negative-binomial.html#introduction",
    "title": "Negative Binomial",
    "section": "",
    "text": "Negative Binomial Regression is used for predicting count data, similar to Poisson Regression, but the Negative Binomial is more flexible as it allows for the variance of the outcome to be greater than its mean (in Poisson Regression, they are assumed to be equal)."
  },
  {
    "objectID": "regressions/negative-binomial.html#uses",
    "href": "regressions/negative-binomial.html#uses",
    "title": "Negative Binomial",
    "section": "Uses",
    "text": "Uses\nNegative Binomial Regression is used to model count data with excess zeros (as in the Zero-Inflated Negative Binomial Regression) and is used to model rare events which are less likely to have counts where mean = variance. Negative Binomial can be extended to handle correlated/clustered data as well."
  },
  {
    "objectID": "regressions/negative-binomial.html#assumptions",
    "href": "regressions/negative-binomial.html#assumptions",
    "title": "Negative Binomial",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe outcome represents count data\nThe variance of the outcome is greater than its mean\nThe relationship between the predictors and the log of the outcome’s mean is linear\nThe errors are independent of one another"
  },
  {
    "objectID": "regressions/negative-binomial.html#our-negative-binomial-regression-implementation",
    "href": "regressions/negative-binomial.html#our-negative-binomial-regression-implementation",
    "title": "Negative Binomial",
    "section": "Our Negative Binomial Regression Implementation",
    "text": "Our Negative Binomial Regression Implementation\nOur Negative Binomial Regression implementation: (Note that we use bootstrapping to estimate standard errors)\n\nnegative_binomial_regression &lt;- function(data, ..., y) {\n  n &lt;- nrow(data)\n  x_parameters &lt;- c(...)\n  # defining the predictor matrix\n  X &lt;-\n    matrix(c(rep(1, n), x_parameters),\n      nrow = n,\n      ncol = ncol(data)\n    )\n  # defining the outcome matrix\n  Y &lt;- matrix(y, nrow = n, ncol = 1)\n  # starting with theta = 1\n  theta &lt;- 1\n  # defining the log likelihood\n  negative_binomial.likelihood &lt;- function(beta, X, Y = y) {\n    eta &lt;- X %*% beta\n    mu &lt;- exp(eta)\n    loglikelihood &lt;-\n      sum(Y * log(mu) - (Y + 1 / theta) * log(1 + mu / theta))\n    return(loglikelihood)\n  }\n  # starting with an initial guess of the parameter values\n  initial_guess &lt;- rep(0, ncol(X))\n  # using 'optim' to maximize the log likelihood\n  result &lt;- optim(\n    initial_guess,\n    negative_binomial.likelihood,\n    X = X,\n    Y = Y,\n    control = list(fnscale = -1),\n    hessian = T,\n    method = NULL\n  )$par\n  # creating a vector 'estimate' for the beta coefficients\n  estimate &lt;- result\n  # bootstrapping to estimate the standard errors\n  num_bootstraps &lt;- 10\n  result_bootstrap &lt;-\n    matrix(0, nrow = num_bootstraps, ncol = ncol(X))\n  for (i in 1:num_bootstraps) {\n    sample_indices &lt;- sample(nrow(data), replace = TRUE)\n    bootstrap_data &lt;- data[sample_indices, ]\n    X_bootstrap &lt;-\n      matrix(\n        c(rep(1, nrow(bootstrap_data)), x_parameters),\n        nrow = nrow(bootstrap_data),\n        ncol = ncol(bootstrap_data)\n      )\n    Y_bootstrap &lt;-\n      matrix(bootstrap_data$y,\n        nrow = nrow(bootstrap_data),\n        ncol = 1\n      )\n    initial_guess_bootstrap &lt;-\n      matrix(0, nrow = ncol(bootstrap_data), ncol = 1)\n    result_bootstrap[i, ] &lt;- optim(\n      initial_guess_bootstrap,\n      negative_binomial.likelihood,\n      X = X_bootstrap,\n      Y = Y_bootstrap,\n      control = list(fnscale = -1),\n      hessian = T,\n      method = NULL\n    )$par\n  }\n  # finding the standard deviation of the bootstrapped betas to find the\n  # standard error of the coefficients\n  se &lt;- apply(result_bootstrap, 2, sd)\n  # calculating the z-statistic\n  z &lt;- estimate / se\n  # defining the degrees of freedom\n  df &lt;- nrow(X) - ncol(X)\n  # calculating the p-value\n  p &lt;- 2 * pnorm(z, lower.tail = FALSE)\n  # defining the row names of the output data frame\n  rownames &lt;- c()\n  for (i in 1:((ncol(X)) - 1)) {\n    rownames[i] &lt;- i\n  }\n  data_to_plot &lt;- data[, -which(colnames(data) == \"y\")]\n  data_to_plot$y_log &lt;- log(data$y)\n  test &lt;- list(\n    pairs(data_to_plot, main = \"Assessing Linearity of Predictors \\nwith log of Outcome\")\n  )\n  impl &lt;- data.frame(\n    Estimate = estimate,\n    Std.Error = se,\n    z.value = z,\n    p.value = p,\n    DegOfFreedom = c(df, rep(NA, ncol(X) - 1)),\n    row.names = c(\"(Intercept)\", paste0(rep(\"x\", ncol(\n      X\n    ) - 1), rownames))\n  )\n  # returning a data frame akin to the glm probit output\n  return(list(test, impl))\n}\n\nCreating a function to predict the outcomes based on our Negative Binomial Regression implementation.\n\npredict_neg_binom &lt;-\n  function(data, ..., y, implementation_neg_binom) {\n    n &lt;-\n      implementation_neg_binom$DegOfFreedom[1] + nrow(implementation_neg_binom)\n    input_covariate_values &lt;- c(...)\n    X &lt;-\n      matrix(\n        c(rep(1, n), input_covariate_values),\n        nrow = n,\n        ncol = nrow(implementation_neg_binom)\n      )\n    Y &lt;- matrix(y, nrow = n, ncol = 1)\n    estimate &lt;-\n      implementation_neg_binom[1:nrow(implementation_neg_binom), 1]\n    pred &lt;- exp(X %*% estimate)\n    return(pred)\n  }\n\nCreating a test data set which meets all Negative Binomial Regression assumptions to check if our function works.\n\nx1 &lt;- rnorm(100, mean = 0, sd = 0.5)\nx2 &lt;- rnorm(100, mean = 0, sd = 0.5)\ny &lt;- rnbinom(100, mu = exp(x1 + x2), size = 0.5)\ntest_neg_binom_regression_data &lt;- data.frame(x1, x2, y)\n# to ensure that the variance of the outcome variable is greater\n# than its mean\nvar(y) &gt; mean(y)\n\n[1] TRUE\n\nplot(test_neg_binom_regression_data$x1, log(test_neg_binom_regression_data$y),\n  main = \"The relationship between the log of the outcome and x1 is linear (it is not apparent in this plot but our data structure captures this relationship)\", cex.main = 0.4,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\nplot(test_neg_binom_regression_data$x2, log(test_neg_binom_regression_data$y),\n  xlab = \"x2\", ylab = \"y\",\n  main = \"The relationship between the log of the outcome and x2 is linear (it is not apparent in this plot but our data structure captures this relationship)\", cex.main = 0.4\n)"
  },
  {
    "objectID": "regressions/negative-binomial.html#testing-assumptions-for-negative-binomial-regression",
    "href": "regressions/negative-binomial.html#testing-assumptions-for-negative-binomial-regression",
    "title": "Negative Binomial",
    "section": "Testing Assumptions for Negative Binomial Regression",
    "text": "Testing Assumptions for Negative Binomial Regression\n\ntest_negbinom_reg &lt;- negative_binomial_regression(test_neg_binom_regression_data,\n  test_neg_binom_regression_data$x1,\n  test_neg_binom_regression_data$x2,\n  y = test_neg_binom_regression_data$y\n)[[1]]\n\n\n\n\n\n\n\n\nUsing our implementation of Negative Binomial to fit the model and get residual measure.\n\nour_implementation_neg_binom &lt;-\n  negative_binomial_regression(\n    test_neg_binom_regression_data,\n    test_neg_binom_regression_data$x1,\n    test_neg_binom_regression_data$x2,\n    y = test_neg_binom_regression_data$y\n  )[[2]]\n\n\n\n\n\n\n\nour_implementation_neg_binom\n\n              Estimate Std.Error  z.value    p.value DegOfFreedom\n(Intercept) 0.07019194 0.4237645 0.165639 0.86844102           97\nx1          1.08333669 0.7137122 1.517890 0.12904208           NA\nx2          1.08402921 0.4776059 2.269715 0.02322489           NA\n\n\nComparing our output to R’s output.\n\nr_implementation_neg_binom &lt;-\n  summary(glm.nb(y ~ x1 + x2, data = test_neg_binom_regression_data))\nr_implementation_neg_binom\n\n\nCall:\nglm.nb(formula = y ~ x1 + x2, data = test_neg_binom_regression_data, \n    init.theta = 0.2843070253, link = log)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.29425  -0.97170  -0.78659  -0.03923   1.85674  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  0.06525    0.21920   0.298   0.7660  \nx1           1.13741    0.48623   2.339   0.0193 *\nx2           1.08214    0.44280   2.444   0.0145 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.2843) family taken to be 1)\n\n    Null deviance: 86.734  on 99  degrees of freedom\nResidual deviance: 75.001  on 97  degrees of freedom\nAIC: 278.94\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.2843 \n          Std. Err.:  0.0718 \n\n 2 x log-likelihood:  -270.9420 \n\n\nWe note that the results are similar.\nWe followed all assumptions of Negative Binomial Regression in regressing y on x1 and x2 using the test_neg_binom_regression_data data set. We will compare the residual of this regression to that of all the others where assumptions will be broken.\nThe residual for where all assumptions are met:\n\nprediction_all_assumptions_met &lt;-\n  as.numeric(\n    predict_neg_binom(\n      test_neg_binom_regression_data,\n      test_neg_binom_regression_data$x1,\n      test_neg_binom_regression_data$x2,\n      y = test_neg_binom_regression_data$y,\n      implementation_neg_binom = our_implementation_neg_binom\n    )\n  )\nresidual_all_assumptions_met &lt;- sqrt(mean((\n  test_neg_binom_regression_data$y - prediction_all_assumptions_met\n)^2))\nresidual_all_assumptions_met # small residual\n\n[1] 3.442564\n\n# residual plot\nplot(\n  test_neg_binom_regression_data$y - prediction_all_assumptions_met,\n  ylim = c(-30, 30),\n  ylab = \"Residuals\",\n  main = \"Residual Plot: All assumptions met\",\n  pch = 16\n)\nabline(\n  h = 0,\n  col = \"red\",\n  lty = 2,\n  lwd = 3\n)"
  },
  {
    "objectID": "regressions/negative-binomial.html#breaking-assumptions",
    "href": "regressions/negative-binomial.html#breaking-assumptions",
    "title": "Negative Binomial",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nBreaking the assumption that the relationship between the predictors and the log of the outcome’s mean is linear\nCreating a data set where, if we apply Negative Binomial regression, this assumption will be broken.\n\nx1 &lt;- rnorm(100, mean = 0, sd = 0.5)\nx2 &lt;- rnorm(100, mean = 0, sd = 0.5)\ny &lt;- rnbinom(100, mu = exp(x1 + x2)^2, size = 0.5)\ntest_neg_binom_regression_data_not_linear &lt;- data.frame(x1, x2, y)\n# to ensure that the variance of the outcome variable is greater\n# than its mean\nvar(y) &gt; mean(y)\n\n[1] TRUE\n\nplot(test_neg_binom_regression_data_not_linear$x1, log(test_neg_binom_regression_data_not_linear$y),\n  main = \"The relationship between the log of the outcome and x1 is not linear\", cex.main = 0.8,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\nplot(test_neg_binom_regression_data_not_linear$x2, log(test_neg_binom_regression_data_not_linear$y),\n  xlab = \"x2\", ylab = \"y\", cex.main = 0.8,\n  main = \"The relationship between the log of the outcome and x2 is not linear\"\n)\n\n\n\n\n\n\n\n\nUsing our implementation of Negative Binomial to fit the model and get a residual measure.\n\nour_implementation_neg_binom_not_linear &lt;-\n  negative_binomial_regression(\n    test_neg_binom_regression_data_not_linear,\n    test_neg_binom_regression_data_not_linear$x1,\n    test_neg_binom_regression_data_not_linear$x2,\n    y = test_neg_binom_regression_data_not_linear$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_not_linear &lt;-\n  as.numeric(\n    predict_neg_binom(\n      test_neg_binom_regression_data_not_linear,\n      test_neg_binom_regression_data_not_linear$x1,\n      test_neg_binom_regression_data_not_linear$x2,\n      y = test_neg_binom_regression_data_not_linear$y,\n      implementation_neg_binom = our_implementation_neg_binom_not_linear\n    )\n  )\nresidual_not_linear &lt;- sqrt(mean((\n  test_neg_binom_regression_data_not_linear$y - prediction_not_linear\n)^2))\nresidual_not_linear # large residual\n\n[1] 7.155735\n\n# residual plot\nplot(\n  test_neg_binom_regression_data_not_linear$y - prediction_not_linear,\n  ylim = c(-30, 30),\n  ylab = \"Residuals\",\n  main = \"Residual Plot: Linearity assumption violated\",\n  pch = 16\n)\nabline(\n  h = 0,\n  col = \"red\",\n  lty = 2,\n  lwd = 3\n)\n\n\n\n\n\n\n\n\n\n\nBreaking the assumption that the mean of the outcome is smaller than its variance\nCreating a data set where, if we apply Negative Binomial regression, this assumption will be broken.\n\nx1 &lt;- rnorm(100, mean = 0, sd = 0.5)\nx2 &lt;- rnorm(100, mean = 0, sd = 0.5)\ny &lt;- rnbinom(100, mu = exp(x2 - 2 * x1), size = 100) + 10\ntest_neg_binom_regression_data_mean_greater &lt;- data.frame(x1, x2, y)\n# to ensure that the variance of the outcome variable is smaller\n# than its mean\nvar(y) &gt; mean(y)\n\n[1] FALSE\n\n\nUsing our implementation of Negative Binomial to fit the model and get a residual measure.\n\nour_implementation_neg_binom_mean_greater &lt;-\n  negative_binomial_regression(\n    test_neg_binom_regression_data_mean_greater,\n    test_neg_binom_regression_data_mean_greater$x1,\n    test_neg_binom_regression_data_mean_greater$x2,\n    y = test_neg_binom_regression_data_mean_greater$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_mean_greater &lt;-\n  as.numeric(\n    predict_neg_binom(\n      test_neg_binom_regression_data_mean_greater,\n      test_neg_binom_regression_data_mean_greater$x1,\n      test_neg_binom_regression_data_mean_greater$x2,\n      y = test_neg_binom_regression_data_mean_greater$y,\n      implementation_neg_binom = our_implementation_neg_binom_mean_greater\n    )\n  )\nresidual_mean_greater &lt;- sqrt(mean((\n  test_neg_binom_regression_data_mean_greater$y - prediction_mean_greater\n)^2))\nresidual_mean_greater\n\n[1] 1.601529\n\n# residual plot\nplot(\n  test_neg_binom_regression_data_mean_greater$y - prediction_mean_greater,\n  ylim = c(-30, 30),\n  ylab = \"Residuals\",\n  cex.main = 0.9,\n  main = \"Residual Plot: Variance of outcome greater than mean assumption violated\",\n  pch = 16\n)\nabline(\n  h = 0,\n  col = \"red\",\n  lty = 2,\n  lwd = 3\n)"
  },
  {
    "objectID": "regressions/negative-binomial.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "href": "regressions/negative-binomial.html#comparing-residuals-when-all-assumptions-were-met-versus-not",
    "title": "Negative Binomial",
    "section": "Comparing residuals when all assumptions were met versus not",
    "text": "Comparing residuals when all assumptions were met versus not\n\nresidual_comparison &lt;-\n  t(\n    data.frame(\n      residual_all_assumptions_met,\n      residual_not_linear,\n      residual_mean_greater\n    )\n  )\nrow.names(residual_comparison) &lt;- c(\n  \"All assumptions met\",\n  \"Linearity assumption violated\",\n  \"Variance &gt; Mean assumption violated\"\n)\ncolnames(residual_comparison) &lt;- \"Residuals\"\nresidual_comparison\n\n                                    Residuals\nAll assumptions met                  3.442564\nLinearity assumption violated        7.155735\nVariance &gt; Mean assumption violated  1.601529"
  },
  {
    "objectID": "regressions/negative-binomial.html#conclusion",
    "href": "regressions/negative-binomial.html#conclusion",
    "title": "Negative Binomial",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation of Negative Binomial Regression where all assumptions are met performs well; however, even the model where an assumption is broken; i.e. where the mean of the outcome is greater than its variance, performs well too - however, it should be noted that even though its predictions might be accurate, its standard errors and p-values might be biased.\n\nset.seed(123)\nlibrary(alr4)\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(pscl)\nlibrary(glmbb) # for crabs data\nlibrary(kableExtra)\nlibrary(lmtest)"
  },
  {
    "objectID": "regressions/probit.html",
    "href": "regressions/probit.html",
    "title": "Probit",
    "section": "",
    "text": "The Probit model classifies observations into one of two categories (for simple Probit Regression; multinomial Probit Regression can classify observations into more than two categories) by estimating the probability that an observation with particular characteristics is more likely to fall in one category or another."
  },
  {
    "objectID": "regressions/probit.html#introduction",
    "href": "regressions/probit.html#introduction",
    "title": "Probit",
    "section": "",
    "text": "The Probit model classifies observations into one of two categories (for simple Probit Regression; multinomial Probit Regression can classify observations into more than two categories) by estimating the probability that an observation with particular characteristics is more likely to fall in one category or another."
  },
  {
    "objectID": "regressions/probit.html#uses",
    "href": "regressions/probit.html#uses",
    "title": "Probit",
    "section": "Uses",
    "text": "Uses\nProbit Regression is primarily used when the outcome is binary - thus, it is mainly used for classification problems. When covariates are continuous, there are infinite possible values for the outcome if using Linear Regression; Logistic and Probit Regressions are therefore better than Linear if we need to bound the outcome to 0 and 1.\nLogistic Regression and Probit Regressions give almost identical results - they just have different link functions. The decision to chose one over the other is discipline-dependent, and it is said that Logistic Regression is better when one has extreme independent variables (where one particular small or large value will overwhelmingly determine if your outcome is 0 or 1 - overriding the effect of most other variables). However, there is no ‘right’ answer to this debate."
  },
  {
    "objectID": "regressions/probit.html#assumptions",
    "href": "regressions/probit.html#assumptions",
    "title": "Probit",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe outcome is binary\nThe z-score of the outcome and the predictor variables have a linear relationship\nThe errors are normally distributed and are independent of one another"
  },
  {
    "objectID": "regressions/probit.html#our-probit-regression-implementation",
    "href": "regressions/probit.html#our-probit-regression-implementation",
    "title": "Probit",
    "section": "Our Probit Regression Implementation",
    "text": "Our Probit Regression Implementation\nOur Probit Regression implementation: (Note that we use bootstrapping to estimate standard errors)\n\nprobit_regression &lt;- function(data, ..., y) {\n  n &lt;- nrow(data)\n  x_parameters &lt;- c(...)\n  # defining the predictor matrix\n  X &lt;-\n    matrix(c(rep(1, n), x_parameters),\n      nrow = n,\n      ncol = ncol(data)\n    )\n  # defining the outcome matrix\n  Y &lt;- matrix(y, nrow = n, ncol = 1)\n  # defining the log likelihood\n  probit.loglikelihood &lt;- function(beta, X, Y) {\n    eta &lt;- X %*% beta\n    p &lt;- pnorm(eta)\n    loglikelihood &lt;- -sum((1 - Y) * log(1 - p) + Y * log(p))\n    return(loglikelihood)\n  }\n  # starting with an initial guess of the parameter values\n  initial_guess &lt;- matrix(0, nrow = ncol(data), ncol = 1)\n  # using 'optim' to maximize the log likelihood\n  result &lt;- optim(\n    initial_guess,\n    fn = probit.loglikelihood,\n    X = X,\n    Y = Y,\n    method = NULL\n  )$par\n  # creating a vector 'estimate' for the beta coefficients\n  estimate &lt;- result\n  # bootstrapping to estimate the standard errors\n  num_bootstraps &lt;- 10\n  result_bootstrap &lt;-\n    matrix(0, nrow = num_bootstraps, ncol = ncol(X))\n  for (i in 1:num_bootstraps) {\n    sample_indices &lt;- sample(nrow(data), replace = TRUE)\n    bootstrap_data &lt;- data[sample_indices, ]\n    X_bootstrap &lt;-\n      matrix(\n        c(rep(1, nrow(bootstrap_data)), x_parameters),\n        nrow = nrow(bootstrap_data),\n        ncol = ncol(bootstrap_data)\n      )\n    Y_bootstrap &lt;-\n      matrix(bootstrap_data$y,\n        nrow = nrow(bootstrap_data),\n        ncol = 1\n      )\n    initial_guess_bootstrap &lt;-\n      matrix(0, nrow = ncol(bootstrap_data), ncol = 1)\n    result_bootstrap[i, ] &lt;- optim(\n      initial_guess_bootstrap,\n      probit.loglikelihood,\n      X = X_bootstrap,\n      Y = Y_bootstrap,\n      method = NULL\n    )$par\n  }\n  # finding the standard deviation of the bootstrapped betas to find the\n  # standard error of the coefficients\n  se &lt;- apply(result_bootstrap, 2, sd)\n  # calculating the z-statistic\n  z &lt;- estimate / se\n  # defining the degrees of freedom\n  df &lt;- nrow(X) - ncol(X)\n  # calculating the p-value\n  p &lt;- 2 * pnorm(z, lower.tail = FALSE)\n  # defining the row names of the output data frame\n  rownames &lt;- c()\n  for (i in 1:((ncol(X)) - 1)) {\n    rownames[i] &lt;- i\n  }\n  data_to_plot &lt;- data[, -which(colnames(data) == \"y\")]\n  data_to_plot$y_zscore &lt;- qnorm(pnorm(data$y))\n  test &lt;- list(\n    pairs(data_to_plot, main = \"Assessing Linearity of Predictors\\n with z score of Outcome\")\n  )\n  impl &lt;- data.frame(\n    Estimate = estimate,\n    Std.Error = se,\n    z.value = z,\n    p.value = p,\n    DegOfFreedom = c(df, rep(NA, ncol(X) - 1)),\n    row.names = c(\"(Intercept)\", paste0(rep(\"x\", ncol(\n      X\n    ) - 1), rownames))\n  )\n  # returning a data frame akin to the glm probit output\n  return(list(test, impl))\n}\n\nCreating a function to predict the outcomes based on our Probit Regression implementation.\n\npredict_probit &lt;-\n  function(data, ..., y, implementation_probit) {\n    n &lt;-\n      implementation_probit$DegOfFreedom[1] + nrow(implementation_probit)\n    input_covariate_values &lt;- c(...)\n    X &lt;-\n      matrix(\n        c(rep(1, n), input_covariate_values),\n        nrow = n,\n        ncol = nrow(implementation_probit)\n      )\n    Y &lt;- matrix(y, nrow = n, ncol = 1)\n    estimate &lt;-\n      implementation_probit[1:nrow(implementation_probit), 1]\n    pred &lt;- ifelse(X %*% estimate &lt; 0, 0, 1)\n    return(pred)\n  }\n\nCreating a test data set which meets all Probit Regression assumptions to check if our function works.\n\ntest_probit_regression_data &lt;- data.frame(\n  x1 = rnorm(1000, 0, 1),\n  x2 = rnorm(1000, 0, 1)\n)\nerror &lt;- rnorm(1000, mean = 0, sd = 0.5)\ntest_probit_regression_data$y &lt;- test_probit_regression_data$x1 +\n  0.5 * test_probit_regression_data$x2 +\n  error\ntest_probit_regression_data$y &lt;-\n  qnorm(pnorm(test_probit_regression_data$y))\n\nplot(test_probit_regression_data$x1, test_probit_regression_data$y,\n  main = \"The z score of y and x1 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\nplot(test_probit_regression_data$x1, test_probit_regression_data$y,\n  main = \"The z score of y and x2 have a linear relationship\", cex.main = 0.6,\n  xlab = \"x2\", ylab = \"y\"\n)\n\n\n\n\n\n\n\ntest_probit_regression_data$y &lt;-\n  ifelse(test_probit_regression_data$y &lt; 0, 0, 1)\n\nplot(density(error), main = \"Errors are normally distributed\")"
  },
  {
    "objectID": "regressions/probit.html#testing-assumptions-for-probit-regression",
    "href": "regressions/probit.html#testing-assumptions-for-probit-regression",
    "title": "Probit",
    "section": "Testing Assumptions for Probit Regression",
    "text": "Testing Assumptions for Probit Regression\n\ntest_probit_reg &lt;- probit_regression(test_probit_regression_data,\n  test_probit_regression_data$x1,\n  test_probit_regression_data$x2,\n  y = test_probit_regression_data$y\n)[[1]]\n\n\n\n\n\n\n\n\nApplying the function we created on this data set.\n\nour_implementation_probit &lt;-\n  probit_regression(\n    test_probit_regression_data,\n    test_probit_regression_data$x1,\n    test_probit_regression_data$x2,\n    y = test_probit_regression_data$y\n  )[[2]]\n\n\n\n\n\n\n\nour_implementation_probit\n\n               Estimate  Std.Error   z.value       p.value DegOfFreedom\n(Intercept) -0.09036983 0.04232593 -2.135094  1.967247e+00          997\nx1           1.99232295 0.03188065 62.493167  0.000000e+00           NA\nx2           1.03345197 0.04472044 23.109165 3.744892e-118           NA\n\n\nComparing our output to R’s output.\n\nr_implementation_probit &lt;-\n  summary(glm(y ~ x1 + x2,\n    data = test_probit_regression_data,\n    family = binomial(link = \"probit\")\n  ))\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nr_implementation_probit\n\n\nCall:\nglm(formula = y ~ x1 + x2, family = binomial(link = \"probit\"), \n    data = test_probit_regression_data)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.82426  -0.34561  -0.00006   0.40909   2.68617  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.09085    0.05918  -1.535    0.125    \nx1           1.99294    0.12348  16.139   &lt;2e-16 ***\nx2           1.03360    0.08103  12.756   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1386.23  on 999  degrees of freedom\nResidual deviance:  586.45  on 997  degrees of freedom\nAIC: 592.45\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe note that the results are similar.\nWe followed all assumptions of Probit Regression in regressing y on x1 and x2 using the test_probit_regression_data data set. We will compare the residual of this regression to that of all the others where assumptions will be broken.\nThe accuracy for where all assumptions are met:\n\nprediction_all_assumptions_met &lt;-\n  as.numeric(\n    predict_probit(\n      test_probit_regression_data,\n      test_probit_regression_data$x1,\n      test_probit_regression_data$x2,\n      y = test_probit_regression_data$y,\n      implementation_probit = our_implementation_probit\n    )\n  )\naccuracy_all_assumptions_met &lt;-\n  sum(prediction_all_assumptions_met == test_probit_regression_data$y) / 1000\naccuracy_all_assumptions_met # high accuracy here\n\n[1] 0.873"
  },
  {
    "objectID": "regressions/probit.html#breaking-assumptions",
    "href": "regressions/probit.html#breaking-assumptions",
    "title": "Probit",
    "section": "Breaking Assumptions",
    "text": "Breaking Assumptions\n\nBreaking the assumption that the relationship between the predictors and the z score of y is linear\nCreating a data set where, if we apply Probit Regression, this assumption will be broken.\n\ntest_probit_regression_data_not_linear &lt;-\n  data.frame(\n    x1 = rnorm(1000, 0, 1),\n    x2 = rnorm(1000, 0, 1)\n  )\neror &lt;- rnorm(1000, mean = 0, sd = 0.5)\ntest_probit_regression_data_not_linear$y &lt;-\n  test_probit_regression_data_not_linear$x1^2 + error\ntest_probit_regression_data_not_linear$y &lt;-\n  qnorm(pnorm(test_probit_regression_data_not_linear$y))\n\nplot(test_probit_regression_data_not_linear$x1, test_probit_regression_data_not_linear$y,\n  main = \"The z score of y and x1 \\ndo not have a linear relationship\",\n  xlab = \"x1\", ylab = \"y\"\n)\n\n\n\n\n\n\n\ntest_probit_regression_data_not_linear$y &lt;-\n  ifelse(test_probit_regression_data_not_linear$y &lt; 0, 0, 1)\n\nUsing our implementation of glm Probit to fit the model and get an accuracy measure.\n\nour_implementation_probit_not_linear &lt;-\n  probit_regression(\n    test_probit_regression_data_not_linear,\n    test_probit_regression_data_not_linear$x1,\n    test_probit_regression_data_not_linear$x2,\n    y = test_probit_regression_data_not_linear$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_not_linear &lt;-\n  as.numeric(\n    predict_probit(\n      test_probit_regression_data_not_linear,\n      test_probit_regression_data_not_linear$x1,\n      test_probit_regression_data_not_linear$x2,\n      y = test_probit_regression_data_not_linear$y,\n      implementation_probit = our_implementation_probit_not_linear\n    )\n  )\naccuracy_not_linear &lt;-\n  sum(prediction_not_linear == test_probit_regression_data_not_linear$y) / 1000\naccuracy_not_linear # lower accuracy here\n\n[1] 0.777\n\n\nWe note that Probit Regression is not performing as well in this case.\n\n\nBreaking the assumption that the errors are normally distributed\nCreating a data set where, if we apply Probit Regression, this assumption will be broken.\n\ntest_probit_regression_data_not_normally_dist &lt;-\n  data.frame(\n    x1 = rnorm(1000, 0, 1),\n    x2 = rnorm(1000, 0, 1)\n  )\nerror &lt;- runif(1000, min = -1, max = 1)\ntest_probit_regression_data_not_normally_dist$y &lt;-\n  test_probit_regression_data_not_normally_dist$x1 + error\ntest_probit_regression_data_not_normally_dist$y &lt;-\n  qnorm(pnorm(test_probit_regression_data_not_normally_dist$y))\n\nplot(density(error), main = \"Errors are not normally distributed\")\n\n\n\n\n\n\n\ntest_probit_regression_data_not_normally_dist$y &lt;-\n  ifelse(test_probit_regression_data_not_normally_dist$y &lt; 0, 0, 1)\n\nUsing our implementation of glm Probit to fit the model and get an accuracy measure.\n\nour_implementation_probit_not_normally_dist &lt;-\n  probit_regression(\n    test_probit_regression_data_not_normally_dist,\n    test_probit_regression_data_not_normally_dist$x1,\n    test_probit_regression_data_not_normally_dist$x2,\n    y = test_probit_regression_data_not_normally_dist$y\n  )[[2]]\n\n\n\n\n\n\n\nprediction_not_normally_dist &lt;-\n  as.numeric(\n    predict_probit(\n      test_probit_regression_data_not_normally_dist,\n      test_probit_regression_data_not_normally_dist$x1,\n      test_probit_regression_data_not_normally_dist$x2,\n      y = test_probit_regression_data_not_normally_dist$y,\n      implementation_probit = our_implementation_probit_not_normally_dist\n    )\n  )\naccuracy_not_normally_dist &lt;-\n  sum(prediction_not_normally_dist == test_probit_regression_data_not_normally_dist$y) / 1000\naccuracy_not_normally_dist # lower accuracy here\n\n[1] 0.814\n\n\nWe note that Probit Regression is not performing as well in this case."
  },
  {
    "objectID": "regressions/probit.html#comparing-accuracies-when-all-assumptions-were-met-versus-not",
    "href": "regressions/probit.html#comparing-accuracies-when-all-assumptions-were-met-versus-not",
    "title": "Probit",
    "section": "Comparing accuracies when all assumptions were met versus not",
    "text": "Comparing accuracies when all assumptions were met versus not\n\naccuracy_comparison &lt;-\n  t(\n    data.frame(\n      accuracy_all_assumptions_met,\n      accuracy_not_linear,\n      accuracy_not_normally_dist\n    )\n  )\nrow.names(accuracy_comparison) &lt;- c(\n  \"All assumptions met\",\n  \"Linearity assumption violated\",\n  \"Normality assumption violated\"\n)\ncolnames(accuracy_comparison) &lt;- \"Accuracy\"\naccuracy_comparison\n\n                              Accuracy\nAll assumptions met              0.873\nLinearity assumption violated    0.777\nNormality assumption violated    0.814"
  },
  {
    "objectID": "regressions/probit.html#conclusion",
    "href": "regressions/probit.html#conclusion",
    "title": "Probit",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation of Probit Regression where all assumptions are met performs the best; i.e. it gives us predictions which are more accurate to the true outcome values."
  }
]